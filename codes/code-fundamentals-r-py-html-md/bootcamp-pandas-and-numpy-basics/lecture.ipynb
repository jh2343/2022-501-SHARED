{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Introduction to Numpy and Pandas <a id='H1'></a>\n",
    "\n",
    "* [Week 4: Introduction to Numpy and Pandas](#H1)\n",
    "* [Packages](#H2)\n",
    "  * [The `import` keyword](#H3)\n",
    "  * [Aliasing](#H4)\n",
    "* [Numpy](#H5)\n",
    "\t* [What is Numpy?](#H6)\n",
    "\t* [Why Numpy?](#H7)\n",
    "\t* [Arrays](#H11)\n",
    "    \t* [Creation](#H12)\n",
    "    \t* [Dimensions](#H13)\n",
    "    \t* [Shape](#H14)\n",
    "    \t* [Data Type](#H15)\n",
    "\t\t* [Abstract Creation](#H16)\n",
    "\t\t* [Shaping](#H23)\n",
    "\t\t* [Copies vs. Views](#H27)\n",
    "\t\t* [Transposition](#H29)\n",
    "\t\t* [Mathematical Operations](#H30)\n",
    "\t\t* [Broadcasting](#H33)\n",
    "\t\t* [Upcasting](#H36)\n",
    "\t\t* [Universal Functions](#H37)\n",
    "\t\t* [Indexing](#H38)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages <a id='H2'></a>\n",
    "\n",
    "* Packages are an important tool that let us use existing code written by others (or ourselves) to accomplish high-level tasks. \n",
    "* There are many packages available for Python, which is part of what makes it so powerful and popular.\n",
    "* Packages are installed using a python \"package manager\"\n",
    "* They typically installed in the `command line` terminal, using either the `conda` or `pip` package managers. For example, \n",
    "   *  `conda install numpy`\n",
    "   *  `python -m pip install numpy`\n",
    "* Packages in python are simply a collection of one or more python `.py` file(s)\n",
    "  * When you install the package, these files are saved to your computer\n",
    "* You can then **import** the code from the packages into your own code and use them. \n",
    "  * This allows us to streamline our code by leveraging the work done by others, and avoid \"reinventing the wheel\".\n",
    "\n",
    "### The `import` keyword <a id='H3'></a>\n",
    "\n",
    "We can include the code from these packages using the `import` keyword. For example, let's import the `math` package, which is already installed on our Base Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all the code from the `math` package is loaded into our working environment. From here, we can use functions and methods from this `math` package in our own code. Let's use the `factorial()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# print 5 factorial using the math package\n",
    "print(math.factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have to use the `math` package name before the function call. Otherwise, we will receive an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'factorial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-637175d621a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfactorial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'factorial' is not defined"
     ]
    }
   ],
   "source": [
    "factorial(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliasing <a id='H4'></a>\n",
    "\n",
    "Typing `math` before every function we want to use can become time-consuming and tedious. Instead, we can use `aliasing` to shorten the package name we write in our code. We use the `as` keyword to dictate we want to refer to the package using a different name in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then perform all the functions we want from the `math` packages but we will treat it as if it were just named `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# print 5 factorial using the math package aliased as \"m\"\n",
    "print(m.factorial(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy <a id='H5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Numpy? <a id='H6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Numpy` is a foundational package used by many data scientists and Python software developers for scientific computing. \n",
    "  \n",
    "*  Its primary function is doing highly efficient linear algebra operations, similar to MATLAB.\n",
    "   *  Because of this, It is the backbone of many other commonly used packages like `pandas` and  `pyTorch`\n",
    "<br/><br/>\n",
    "*  Numpy provides for the creation of multidimensional arrays (e.g. vectors, matrices, and tensors) objects that are abstract enough for virtually any task. \n",
    "*  This package also provides functions for speedy operations on arrays ranging from simple matrix multiplication to discrete Fourier transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Numpy? <a id='H7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` is **fast**. In fact, code written with `numpy` would be way faster than if we were to implement the same code using Basic Python lists. As a short background, Python is written in `C`, one of the most efficient (and complicated) languages today. Even though it was created in the early 1970's, it still remains common today for developers trying to achieve the most optimal and speedy code. The caveat here is that `numpy` is optimized to breakdown our code into `C` code at a faster rate than Base Python. Using this package certainly comes with some restrictions but the speed of this package much outweighs the limited freedoms. The Benchmark Comparison from `The Computer Language Benchmarks Game` shows just how fast C is compared to other common programming languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Benchmarks.png](.\\images\\Benchmarks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One other important, and highly efficient, computer language is Fortran. Similar to C, it is also popular in many computational science disciplines. However, due to its complexity, Fortran will not be discussed in this program.\n",
    "\n",
    "`Numpy` leverages various important techniques from the field of high performance computing (HCP). This is the main reason it is so fast. These include concepts such as hyper-threading, vectorization, contiguous memory allocation, and the use of highly optimized linear algebra libraries such as BLAS and Intel's math kernel library. \n",
    "\n",
    "To prove that `numpy` is much faster than base Python methods, two scripts have been implemented below, one for Base Python and one for `numpy`. The overall goal is to compute the matrix multiplication of two $200 \\times 200$ matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Python Matrix Multiplication <a id='H8'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time  # this is another package that utilizes time-related functions\n",
    "\n",
    "# save dimension as a variable\n",
    "dims = 200\n",
    "\n",
    "# create 2 random 200x200 matrices\n",
    "matrix1 = [[numpy.random.randint(0,10) for i in range(dims)] for j in range(dims)]\n",
    "matrix2 = [[numpy.random.randint(0,10) for i in range(dims)] for j in range(dims)]\n",
    "\n",
    "# start the timer \n",
    "baseStart = time.time()\n",
    "\n",
    "# create a 200x200 matrix of zeros to hold the resulting matrix\n",
    "myBaseMatrix = [[0]*dims]*dims\n",
    "\n",
    "# matrix multiplication using base Python and for loops\n",
    "for i in range(dims):\n",
    "    for j in range(dims):\n",
    "        for k in range(dims): \n",
    "            myBaseMatrix[i][j] += matrix1[i][k] * matrix2[k][j]\n",
    "\n",
    "# end the timer \n",
    "baseEnd = time.time()\n",
    "\n",
    "# substract the endtime from the start time\n",
    "baseTime = baseEnd - baseStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Numpy Matrix Multiplication <a id='H9'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dimension as a variable\n",
    "dims = 200\n",
    "\n",
    "# create 2 random 200X200 matrices\n",
    "matrix1 = numpy.random.randint(0,10, size = (dims,dims))\n",
    "matrix2 = numpy.random.randint(0,10, size = (dims,dims))\n",
    "\n",
    "# start the timer \n",
    "numpyStart = time.time()\n",
    "\n",
    "# Perform matrix multiplcation\n",
    "myNumpyMatrix = numpy.matmul(matrix1,matrix2)\n",
    "\n",
    "# end the timer \n",
    "numpyEnd = time.time()\n",
    "\n",
    "# substract the endtime from the start time\n",
    "numpyTime = numpyEnd - numpyStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Compare the Results <a id='H10'></a>\n",
    "\n",
    "We see here that `numpy` blows our base Python algorithm out of the water. Hopefully, this shows just how important `numpy`is to data scientists and software developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Python Time: 2.55497 microseconds\n",
      "Numpy Time: 0.01400 microseconds\n",
      "\n",
      "Numpy is 182.505 times as fast as Python\n"
     ]
    }
   ],
   "source": [
    "# print the results\n",
    "print(f'Base Python Time: {baseTime:.5f} microseconds')\n",
    "print(f'Numpy Time: {numpyTime:.5f} microseconds')\n",
    "print(f'\\nNumpy is {baseTime/numpyTime:.3f} times as fast as Python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays <a id='H11'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's import `numpy`. The common alias for this package is `np` as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation <a id='H12'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a numpy array from an existing Python list is relatively simple. We can use the `np.array()` function to transform a list. Another argument that can be used to specify the specific data type we want. For this implementation, we simply use `\"i\"` which is an integer that usually defaults to 32 or 64 `bits` or \"memory\" to store the number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "myList = [1,2,3,4,5,6]\n",
    "myArray = np.array(myList, dtype = 'i')\n",
    "print(myArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this introduces a new data type to python ('numpy.ndarray'). Similar to those discuss during the week two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(myList))\n",
    "print(type(myArray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions <a id='H13'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ndim` attribute of a Numpy array object tells us how many dimensions our data is. Since only a simple list was passed into the `np.array()` function, the array will have 1 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myArray.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we pass a 2-dimensional list, or a list of lists into the `np.array()` function, we will have created a matrix with rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "myList = [[1,2,3],[4,5,6]]\n",
    "myArray = np.array(myList, dtype = 'i')\n",
    "print(myArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the dimensions of our array should be 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myArray.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the notable restrictions in the `numpy` package is that our 2-dimensional list must be **complete**. If we pass in a list of lists where one list has `3` elements and another only has `2` elements, we get an error. Some exceptions in `numpy` can be confusing so be sure to check your bases when you are creating `numpy` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-09972e96b899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmyList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# PYthon list is not complete, will not work with numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmyArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "myList = [[1,2,3],[4,5]]   # PYthon list is not complete, will not work with numpy\n",
    "\n",
    "myArray = np.array(myList, dtype = 'i')\n",
    "\n",
    "print(myArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape <a id='H14'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `shape` is an important attribute of \"numpy array\" python objects. It is a **tuple** that tells us how many elements are in each dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One dimensional arrays only require one index to specify a given site in the data structure. These are known as Numpy vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n",
      "(3,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "myVector = np.array([4,5,6])\n",
    "print(myVector)\n",
    "print(myVector.shape)\n",
    "print(myVector.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 2-dimensional arrays (i.e. matrices), the shape corresponds to the number of rows and columns of the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]] \n",
      "\n",
      "2 ROWS AND 3 COLUMNS\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "myList = [[1,2,3],[4,5,6]]               # 2 dimensional python list\n",
    "myArray = np.array(myList, dtype = 'i')\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print(\"2 ROWS AND 3 COLUMNS\")\n",
    "print(myArray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a vector can also be represented as a matrix, where one of its axis has length one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5 6]]\n",
      "(1, 3)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#ROW VECTOR (1 ROW AND 3 COLUMNS )\n",
    "myVector = np.array([[4,5,6]])\n",
    "print(myVector)\n",
    "print(myVector.shape)\n",
    "print(myVector.ndim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4]\n",
      " [5]\n",
      " [6]]\n",
      "(3, 1)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#COLUMN VECTOR (3 ROWS AND 1 COLUMN)\n",
    "myVector = np.array([[4],[5],[6]])\n",
    "print(myVector)\n",
    "print(myVector.shape)\n",
    "print(myVector.ndim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For higher dimensions (known as tensors), it can be harder to conceptualize (and visualize). However, the \"shape\" attribute will always be a **tuple** that has a length equal to the number of dimensions, `ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]] \n",
      "\n",
      "(2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "myList = [[[1,2],[3,4]],[[5,6],[7,8]]]  # 3 dimensional python list\n",
    "myArray = np.array(myList, dtype = 'i')\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print(myArray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data structure is technically known as a rank three tensor, it can be visualized as a cube of data. Tensors with rank higher than three become impossible to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Type <a id='H15'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The np.array object's `dtype` attribute tells us what kind of data is stored in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't specify the `dtype` argument when we create the array, `numpy` will usually find the best data type to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] \n",
      "\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "myList = [[1.0,2.0,3.0],[4,5,6]]\n",
    "myArray = np.array(myList)\n",
    "print(myArray, '\\n')\n",
    "\n",
    "print(myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many `dtypes` that can be used but when creating an array, these will be the most common data types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Type | Default Size  |Interpretation \n",
    ":---- | :---- | :---- \n",
    "`i`  | 32 bits |Integer\n",
    "`b`  | 8 bits | Boolean\n",
    "`uint`  | 32 bits | Unsigned Integer\n",
    "`f`  | 64 bits | Floating Point Number\n",
    "`M`  | 64 bits | DateTime\n",
    "`O`  | Depends on Input | Any Pythonic object\n",
    "`S`  | Depends on Input | String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract Creation <a id='H16'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.ones/np.zeros <a id='H17'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times, we don't want to explicitly define a `numpy` array using a list. The `np.ones()` and `np.zeros()` functions let us initialize an array of either `1's` or `0's`. By default, the data type of the created arrays are `float64`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1.] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (6,)\n",
      "dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "myArray = np.ones(6)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass a `shape` argument into these functions, which must be a tuple defining the length of each dimension. In this case, we ask for `3` rows and `4` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 4)\n",
      "dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "myArray = np.zeros(shape = (3,4))\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.full <a id='H18'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.full()` function is similar to the `np.ones()` and `np.zeros()` function. However, it lets us choose what value to fill the array with. For this method, `shape` is the first argument of the function, and the `fill_value` argument dictates what value to fill the array with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 7 7 7]\n",
      " [7 7 7 7]\n",
      " [7 7 7 7]] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 4)\n",
      "dtype:  int32\n"
     ]
    }
   ],
   "source": [
    "myArray = np.full(shape = (3,4), fill_value = 7)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.arange <a id='H19'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.arange()` function lets us make an array that contains values in a range. By default, if a single number is provided as an argument, it returns an array of integers starting at 0 and ending right before the number in the argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (8,)\n",
      "dtype:  int32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(8)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we specify `2` arguments, then the values in the created array will start at the first argument and end right before the second argument. This is because Python is always inclusive on the left and exclusive on the right, as was described in week two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8 9] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (7,)\n",
      "dtype:  int32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(3,10)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we only want even numbers between 0 and 10. We can use a third argument, `step`, that tells `numpy` the step size to use. By default, the step size is `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4 6 8] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (5,)\n",
      "dtype:  int32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(0,10, step = 2)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.random.random <a id='H20'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` also has a `random` package inside. This package lets us create arrays with pseudo-random numbers. The `np.random.random()`function lets us make an array of a certain length, with numbers that are uniformly distributed between `0` and `1`.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81772666 0.2709232  0.93851005 0.21763722 0.97388142 0.48873547\n",
      " 0.27544629 0.73570215] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (8,)\n",
      "dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "myArray = np.random.random(8)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create matrices or tensors by inputting a tuple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.86660377 0.44520249 0.07740186]\n",
      " [0.49993227 0.26216785 0.48643139]]\n"
     ]
    }
   ],
   "source": [
    "myArray = np.random.random((2,3))\n",
    "print(myArray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### np.astype <a id='H21'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may want to change the data type of our array (typecasting). This can be accomplished using the `astype()` function. Here we pass `f` into the `dtype` argument. The resulting array now has floating point number as its data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (8,)\n",
      "dtype:  int32 \n",
      "\n",
      "--Casting myArray to type float--\n",
      "\n",
      "[0. 1. 2. 3. 4. 5. 6. 7.] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (8,)\n",
      "dtype:  float32\n"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(8)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "print(\"--Casting myArray to type float--\\n\")\n",
    "myArray = myArray.astype(dtype = 'f')\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some considerations to keep in mind when changing the data type of an array. When we change the data type to a type that is less precise, we lose data. This is called `downcasting`. In the example below, we cast our floating point array as an integer array. In this case, we lose the decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.14159 2.71828] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (2,)\n",
      "dtype:  float64 \n",
      "\n",
      "--Casting myArray to type int--\n",
      "\n",
      "[3 2] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (2,)\n",
      "dtype:  int32\n"
     ]
    }
   ],
   "source": [
    "myArray = np.array([3.14159,  2.71828])\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "print(\"--Casting myArray to type int--\\n\")\n",
    "myArray = myArray.astype(dtype = 'i')\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaping <a id='H23'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shaping in `numpy` lets us changes the dimension and shape of our arrays without altering the elements within the array. \n",
    "* Shaping operations are important in many applications including neural networks and deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.reshape <a id='H24'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.reshape()` function lets us choose a new shape of our array. \n",
    "* For example, we can reshape a 1-dimensional array with `9` elements into a $3\\times 3$ array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (9,)\n",
      "dtype:  int32 \n",
      "\n",
      "--Reshaping myArray to (3,3)--\n",
      "\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(9)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "print(\"--Reshaping myArray to (3,3)--\\n\")\n",
    "myArray = myArray.reshape(3,3)\n",
    "\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the new shape that we define using the `shape` argument must be able to \"fit\" the array we are reshaping. \n",
    "\n",
    "Consider what happens when we try to reshape a 1-dimensional array with `8` elements into a  $3\\times 3$  array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] \n",
      "\n",
      "ndims:  1\n",
      "shape:  (8,)\n",
      "dtype:  int32 \n",
      "\n",
      "--Reshaping myArray to (3,3)--\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 8 into shape (3,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-7202baed8741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"--Reshaping myArray to (3,3)--\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmyArray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmyArray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 8 into shape (3,3)"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(8)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "print(\"--Reshaping myArray to (3,3)--\\n\")\n",
    "myArray = myArray.reshape(3,3)\n",
    "\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Axis <a id='H22'></a>\n",
    "\n",
    "* In Numpy, the \"axis\" specifies which dimension you want to perform a specific operation across. \n",
    "\n",
    "* For example, whether you want to sum down the Row (axis=0), or across the columns (axis=1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "SUM DOWN THE ROWS (AXIS=0)\n",
      "[5 7 9]\n",
      "SUM ACROSS THE COLUMNS (AXIS=1)\n",
      "[ 6 15]\n"
     ]
    }
   ],
   "source": [
    "myArray = np.array([[1,2,3],[4,5,6]])\n",
    "print(myArray)\n",
    "print(\"SUM DOWN THE ROWS (AXIS=0)\")\n",
    "print(myArray.sum(axis=0))\n",
    "print(\"SUM ACROSS THE COLUMNS (AXIS=1)\")\n",
    "print(myArray.sum(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.concatenate <a id='H25'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.concatenate()` function lets us combine two arrays. Note that we must wrap the two arrays in a tuple or list for this function. The `axis` argument tells `numpy` which dimension to concatenate the arrays on. Since these arrays are only `1` dimension, we must call `axis = 0`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [0 1 2 3 4] (5,)\n",
      "b: [4 3 2 1 0] (5,)\n",
      "\n",
      "a + b = [0 1 2 3 4 4 3 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(5)\n",
    "b = np.arange(5)[::-1]\n",
    "\n",
    "\n",
    "print('a:',a,a.shape)\n",
    "print('b:',b,b.shape)\n",
    "\n",
    "myConcatArray = np.concatenate( [a, b] ,  axis = 0)\n",
    "\n",
    "print('\\na + b =',myConcatArray)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating multi-dimensional arrays can become more complex. Trying to concatenate two arrays on an incorrect `axis` will raise an error, and is a common error for both beginners and professionals. With more practice, it becomes easier to identify which `axis` to transform on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[0 1 2]\n",
      " [3 4 5]] \n",
      "\n",
      "b:\n",
      " [[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n",
      "\n",
      "a concatenated with b\n",
      " [[0 1 2 0 1 2 3 4]\n",
      " [3 4 5 5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = np.arange(6).reshape(2,3)\n",
    "b = np.arange(10).reshape(2,5)\n",
    "\n",
    "\n",
    "print('a:\\n',a,'\\n')\n",
    "print('b:\\n',b)\n",
    "\n",
    "#ACCROSS THE ROWS \n",
    "myConcatArray = np.concatenate( [a, b] ,  axis = 1)\n",
    "\n",
    "print('\\na concatenated with b\\n',myConcatArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[0 1]\n",
      " [2 3]\n",
      " [4 5]] \n",
      "\n",
      "b:\n",
      " [[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n",
      "\n",
      "a concatenated with b\n",
      " [[0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [0 1]\n",
      " [2 3]\n",
      " [4 5]\n",
      " [6 7]\n",
      " [8 9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = np.arange(6).reshape(3,2)\n",
    "b = np.arange(10).reshape(5,2)\n",
    "\n",
    "\n",
    "print('a:\\n',a,'\\n')\n",
    "print('b:\\n',b)\n",
    "\n",
    "#DOWN THE COLUMNS\n",
    "myConcatArray = np.concatenate( [a, b] ,  axis = 0)\n",
    "\n",
    "print('\\na concatenated with b\\n',myConcatArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.ravel/np.flatten <a id='H26'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.ravel()` and `np.flatten()` functions perform the exact same operation. They both turn a multi-dimensional array into a 1-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "myArray.ravel(): [0 1 2 3 4 5 6 7 8] \n",
      "\n",
      "myArray.flatten(): [0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "myArray = np.arange(9). reshape(3,3)\n",
    "\n",
    "print(myArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "\n",
    "print('myArray.ravel():', myArray.ravel(), '\\n')\n",
    "print('myArray.flatten():', myArray.flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between these two methods is that `np.ravel()` generally returns a `view` while `np.flatten()` returns a `copy`. \n",
    "\n",
    "The meaning of this will be discussed in more detail in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copies vs. Views <a id='H27'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever performing an operation on a `numpy` array and an array is returned, the array is either a `view` or a `copy`. A copy is relatively simple to understand. An entirely new portion of memory is allocated for this new array and all of the elements from the original array are copied to this new array. A `view`, however, is slightly more complex. When we create a `view`, the resulting array shares `memory` with the original array. This can get quite complicated but this means if we change the contents of the original array, the new array that is a `view` will also be affected by the change. The example below shows this phenomenon. A $3\\times 3$ array is created and a `view` is returned from using the `np.ravel()` function. One element in the original array is changed. It can be seen that this change *also* affects the `view`. \n",
    "\n",
    "This may seem strange, however it can be very useful. Often when using large data (arrays), the amount of available computer memory (RAM) becomes a limitation.\n",
    "\n",
    "Therefore, it is much more efficient to point to existing data in the memory rather than making a copy, which would waste memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "--Using ravel() function to create a view--\n",
      "\n",
      "Array View:\n",
      " [0 1 2 3 4 5 6 7 8] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "--Altering the Original Array--\n",
      "\n",
      "Original Array:\n",
      " [[242   1   2]\n",
      " [  3   4   5]\n",
      " [  6   7   8]] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "Array View:\n",
      " [242   1   2   3   4   5   6   7   8] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myOriginalArray = np.arange(9).reshape(3,3)\n",
    "\n",
    "print('Original Array:\\n', myOriginalArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "# use the ravel() function which returns a view\n",
    "print(\"--Using ravel() function to create a view--\\n\")\n",
    "myArrayView = myOriginalArray.ravel()\n",
    "\n",
    "print('Array View:\\n', myArrayView, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "# change the top left corner of the original matrix to 242\n",
    "print(\"--Altering the Original Array--\\n\")\n",
    "myOriginalArray[0,0] = 242 \n",
    "\n",
    "print('Original Array:\\n', myOriginalArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "# print the array view to see that the data has changed\n",
    "print('Array View:\\n', myArrayView, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we never altered `myArrayView`, it was still affected by changes performed on `myOriginalArray`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### np.copy <a id='H28'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.copy()` function can help mitigate some headaches when it comes to deciphering whether a returned array is a `copy` or a `view`. In the example, the new array is unaffected by changes in the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array:\n",
      " [0 1 2 3 4 5] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "--Using copy() function to create a copy--\n",
      "\n",
      "Copied Array:\n",
      " [0 1 2 3 4 5] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "--Altering the Original Array--\n",
      "\n",
      "Original Array:\n",
      " [242   1   2   3   4   5] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n",
      "Copied Array:\n",
      " [0 1 2 3 4 5] \n",
      "\n",
      "ndims:  2\n",
      "shape:  (3, 3)\n",
      "dtype:  int32 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "myOriginalArray = np.arange(6)\n",
    "\n",
    "print('Original Array:\\n',myOriginalArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "# copy() the original array\n",
    "print(\"--Using copy() function to create a copy--\\n\")\n",
    "myArrayCopy = myOriginalArray.copy()\n",
    "\n",
    "print('Copied Array:\\n',myArrayCopy, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "# change the first element of the original matrix to 242\n",
    "print(\"--Altering the Original Array--\\n\")\n",
    "myOriginalArray[0] = 242 \n",
    "\n",
    "print('Original Array:\\n',myOriginalArray, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')\n",
    "\n",
    "# print the array view to see that the data has changed\n",
    "print('Copied Array:\\n',myArrayCopy, '\\n')\n",
    "print('ndims: ', myArray.ndim)\n",
    "print('shape: ',myArray.shape)\n",
    "print('dtype: ',myArray.dtype, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposition <a id='H29'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing an array is an important linear algebra operation. \n",
    "\n",
    "The process of transposing in `Numpy` can be accomplished with the `transpose()` method function. \n",
    "\n",
    "This creates a `view` of the original array that has a shape equal to the reverse of the original array's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = (1, 2, 3, 4, 5)\n",
      "\n",
      "a_transpose.shape = (5, 4, 3, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros(shape = (1,2,3,4,5))\n",
    "print(\"a.shape =\",a.shape)\n",
    "\n",
    "a_transpose = a.transpose()                      # the transpose is a view\n",
    "print(\"\\na_transpose.shape =\",a_transpose.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In two dimensions, transposition can be interpreted and visualized as flipping the values of the array across the main `diagonal` of the array. \n",
    "\n",
    "This means that the rows become the columns i.e. $Transpose(A_{ij})=A_{ji}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = (3, 4)\n",
      "a:\n",
      " [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n",
      "\n",
      "a.shape = (4, 3)\n",
      "a:\n",
      " [[ 0  4  8]\n",
      " [ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3,4)\n",
    "print(\"a.shape =\",a.shape)\n",
    "print('a:\\n',a)\n",
    "\n",
    "a = a.transpose()                      # the transpose is a view\n",
    "print(\"\\na.shape =\",a.shape)\n",
    "print('a:\\n',a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Operations <a id='H30'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` also allows for a variety of numeric and logical operations on over two arrays. \n",
    "\n",
    "These operations are performed **element-wise**, also known as **component-wise**. \n",
    "\n",
    "This means that the resulting array from the operation is composed by performing the operation on each of element of one array with the corresponding element from another array.\n",
    "\n",
    "$$ $$\n",
    "\n",
    "$$\\begin{bmatrix} 3 & 1 & 5 \\\\ 2 & 4 & 0 \\\\ 0 & 1 & 5 \\end{bmatrix} + \\begin{bmatrix} 2 & 2 & 1 \\\\ 3 & 0 & 1 \\\\ 0 & 2 & 4 \\end{bmatrix} = \\begin{bmatrix} 5 & 3 & 6 \\\\ 5 & 4 & 1 \\\\ 0 & 3 & 9 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical Operations <a id='H31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows a list of commonly used numerical operations for `numpy` arrays. These operations will always return a new array with a numeric data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algebraic Operator | numpy Operator | Sample condition | Interpretation\n",
    ":---- | :---- | :---- | :----\n",
    "$\\times$  | `*` | `x * y` | `x` times `y`\n",
    "`/`  | `/` | `x / y` | `x` divided by `y`\n",
    "`+` | `+` | `x + y` | `x` plus `y`\n",
    "`-` | `-` | `x - y` | `x` minus `y`\n",
    "`^` | `**` | `x ** y` | `x` to the power of `y`\n",
    "`mod` | `%` | `x % y` | `x` modulo `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [1 2 3 4 5 6] \n",
      "\n",
      "b:\n",
      " [6 5 4 3 2 1] \n",
      "\n",
      "\n",
      "a + b:\n",
      " [7 7 7 7 7 7]\n",
      "\n",
      "a * b:\n",
      " [ 6 10 12 12 10  6]\n",
      "\n",
      "a ** b:\n",
      " [ 1 32 81 64 25  6]\n",
      "\n",
      "a % b:\n",
      " [1 2 3 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,7)\n",
    "b = np.arange(1,7)[::-1]\n",
    "\n",
    "print('a:\\n', a, '\\n')\n",
    "print('b:\\n', b, '\\n')\n",
    "\n",
    "print('\\na + b:\\n', a + b)\n",
    "print('\\na * b:\\n', a * b)\n",
    "print('\\na ** b:\\n', a ** b)\n",
    "print('\\na % b:\\n', a % b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that this **element-wise** operation property requires that our arrays have the same shape. Failing to ensure the two arrays have the same shape either results in a `runtime error`, where the code stops running, or a `logical error`, where the output array is not as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = (5,)\n",
      "a:\n",
      " [1 2 3 4 5] \n",
      "\n",
      "b.shape = (6,)\n",
      "b:\n",
      " [6 5 4 3 2 1] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,) (6,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a8a9303a7655>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b:\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\na + b:\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,) (6,) "
     ]
    }
   ],
   "source": [
    "a = np.arange(1,6)\n",
    "b = np.arange(1,7)[::-1]\n",
    "\n",
    "print(\"a.shape =\",a.shape)\n",
    "print('a:\\n', a, '\\n')\n",
    "\n",
    "print(\"b.shape =\",b.shape)\n",
    "print('b:\\n', b, '\\n')\n",
    "\n",
    "print('\\na + b:\\n', a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logical Operations <a id='H32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows a list of commonly used logical operations for `numpy` arrays. These operations will always return a new array with the boolean data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algebraic Operator | numpy Operator | Sample condition | Interpretation\n",
    ":---- | :---- | :---- | :----\n",
    "&gt;  | `>` | `x > y` | `x` is greater than `y`\n",
    "&lt;  | `<` | `x < y` | `x` is less than `y`\n",
    "&ge; | `>=` | `x >= y` | `x` is greater than or equal to `y`\n",
    "&le; | `<=` | `x <= y` | `x` is less than or equal to `y`\n",
    "= | `==` | `x == y` | `x` is equal to `y`\n",
    "&ne; | `!=` | `x != y` | `x` is not equal to `y`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]] \n",
      "\n",
      "b:\n",
      " [[8 7 6]\n",
      " [5 4 3]\n",
      " [2 1 0]] \n",
      "\n",
      "a < b:\n",
      "\n",
      " [[ True  True  True]\n",
      " [ True False False]\n",
      " [False False False]]\n",
      "\n",
      "a == b:\n",
      "\n",
      " [[False False False]\n",
      " [False  True False]\n",
      " [False False False]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(9).reshape(3,3)\n",
    "b = np.arange(9)[::-1].reshape(3,3)\n",
    "\n",
    "print('a:\\n', a, '\\n')\n",
    "print('b:\\n', b, '\\n')\n",
    "\n",
    "print('a < b:\\n\\n',a < b)\n",
    "print('\\na == b:\\n\\n',a == b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting <a id='H33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all array operations have to use two arrays of the same shape. `Broadcasting` allows for us to implement some operations much easier. \n",
    "\n",
    "Consider the case where we want multiply to each element of an array by `2`. Certainly this example will get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [1 2 3]\n",
      "b:\n",
      " [2 2 2]\n",
      "\n",
      "a * b:\n",
      " [2 4 6]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4)\n",
    "print('a:\\n',a)\n",
    "\n",
    "b = np.full(3,2)\n",
    "print('b:\\n',b)\n",
    "\n",
    "print('\\na * b:\\n',a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the shape of an array can be repeated and duplicated to fit the size of another array, we can use `broadcasting` to perform an operation on arrays of different sizes.\n",
    "\n",
    " In the example below, `2` is treated as a $1\\times 1$ array and is `stretched` to fit the shape of `a`, which will result in an element-wise operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Broadcasting Example 1](.\\images\\broadcasting_1.png)\n",
    "$$\\text{Source: }\\href{ https://numpy.org/doc/stable/user/basics.broadcasting.html}{numpy.org}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [1 2 3]\n",
      "\n",
      "b:  2\n",
      "\n",
      "a * b:\n",
      " [2 4 6]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,4)\n",
    "print('a:\\n',a)\n",
    "\n",
    "b = 2\n",
    "print('\\nb: ',b)\n",
    "\n",
    "print('\\na * b:\\n',a * b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting Rules <a id='H34'></a>\n",
    "\n",
    "Testing compatibility of two arrays for `broadcasting` can be summed up in 2 rules:\n",
    "\n",
    "\n",
    "* If two array don't have the same number of dimensions, then the shape of the array with a lower number of dimensions is `prepended` with 1's until the number of dimensions. Consider the following case.\n",
    "\n",
    "        a.shape = (3,2,3)\n",
    "        b.shape = (2,3)\n",
    "    \n",
    "    Because `b` has a lower number of dimensions that `a`, a 1 is prepended on the shape of `b` until the number of dimensions match\n",
    "\n",
    "        a.shape = (3,2,3)\n",
    "        b.shape = (1,2,3)      <- 1 has been prepended to the shape of b\n",
    "    \n",
    "* Arrays are compatible only if in each dimension one of these conditions are true:\n",
    "    * the size of at least one of the dimensions is 1\n",
    "    * the size of the dimensions are equal\n",
    "\n",
    "            The following arrays are compatible\n",
    "            a.shape = (2,3,3)\n",
    "            b.shape = (1,3,3)\n",
    "            \n",
    "            The following arrays are NOT compatible\n",
    "            a.shape = (2,3,3)\n",
    "            b.shape = (1,3,4)\n",
    "                           X   <- Last dimensions are not equal and neither of them are 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Examples <a id='H35'></a>\n",
    "\n",
    "We can get more complex with this concept. We can add an array of length $3$ to a $4\\times 3$ array. Let's check for compatibility.\n",
    "\n",
    "* The number of the dimensions are not the same for both arrays\n",
    "    * prepend a 1 to the shape of smaller array, it is now a $1 \\times 3$ array\n",
    "* In the first dimension, at least one of them dimensions has a size of 1\n",
    "* In the second dimension, the sizes of the dimensions are equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Broadcasting Example 2](.\\images\\broadcasting_2.png)\n",
    "$$\\text{Source: }\\href{ https://numpy.org/doc/stable/user/basics.broadcasting.html}{numpy.org}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = (4, 3)\n",
      "a:\n",
      " [[ 0.  0.  0.]\n",
      " [10. 10. 10.]\n",
      " [20. 20. 20.]\n",
      " [30. 30. 30.]]\n",
      "\n",
      "b.shape = (3,)\n",
      "b:\n",
      " [1 2 3]\n",
      "\n",
      "a + b:\n",
      " [[ 1.  2.  3.]\n",
      " [11. 12. 13.]\n",
      " [21. 22. 23.]\n",
      " [31. 32. 33.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[ 0.0,  0.0,  0.0],\n",
    "           [10.0, 10.0, 10.0],\n",
    "           [20.0, 20.0, 20.0],\n",
    "           [30.0, 30.0, 30.0]])\n",
    "print(\"a.shape =\",a.shape)\n",
    "print('a:\\n',a)\n",
    "\n",
    "b = np.arange(1,4)\n",
    "print(\"\\nb.shape =\",b.shape)\n",
    "print('b:\\n',b)\n",
    "\n",
    "print('\\na + b:\\n',a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we can't add an array of length $4$ to a $4\\times 3$ array. Let's check for compatibility and see why.\n",
    "\n",
    "* The number of the dimensions are not the same for both arrays\n",
    "    * prepend a 1 to the shape of smaller array, it is now a $1 \\times 4$ array\n",
    "* In the first dimension, at least one of them dimensions has a size of 1\n",
    "* In the second dimension, the sizes of the dimensions are NOT equal nor does at least one of them have a size of 1\n",
    "\n",
    "![Broadcasting Example 3](.\\images\\broadcasting_3.png)\n",
    "$$\\text{Source: }\\href{ https://numpy.org/doc/stable/user/basics.broadcasting.html}{numpy.org}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = (4, 3)\n",
      "a:\n",
      " [[ 0.  0.  0.]\n",
      " [10. 10. 10.]\n",
      " [20. 20. 20.]\n",
      " [30. 30. 30.]]\n",
      "\n",
      "b.shape = (4,)\n",
      "b:\n",
      " [1 2 3 4]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,3) (4,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-34135da6caf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b:\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\na + b:\\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,3) (4,) "
     ]
    }
   ],
   "source": [
    "a = np.array([[ 0.0,  0.0,  0.0],\n",
    "           [10.0, 10.0, 10.0],\n",
    "           [20.0, 20.0, 20.0],\n",
    "           [30.0, 30.0, 30.0]])\n",
    "print(\"a.shape =\",a.shape)\n",
    "print('a:\\n',a)\n",
    "\n",
    "b = np.arange(1,5)\n",
    "print(\"\\nb.shape =\",b.shape)\n",
    "print('b:\\n',b)\n",
    "\n",
    "print('\\na + b:\\n',a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to add an array of length $3$ to a $4\\times 1$ array. Let's check for compatibility.\n",
    "\n",
    "* The number of the dimensions are not the same for both arrays\n",
    "    * prepend a 1 to the shape of smaller array, it is now a $1 \\times 3$ array\n",
    "* In the first dimension, at least one of them dimensions has a size of 1\n",
    "* In the second dimension, at least one of them dimensions has a size of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Broadcasting Example 4](.\\images\\broadcasting_4.png)\n",
    "$$\\text{Source: }\\href{ https://numpy.org/doc/stable/user/basics.broadcasting.html}{numpy.org}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.shape = (4, 1)\n",
      "a:\n",
      " [[ 0]\n",
      " [10]\n",
      " [20]\n",
      " [30]]\n",
      "\n",
      "b.shape = (3,)\n",
      "b:\n",
      " [1 2 3]\n",
      "\n",
      "a + b:\n",
      " [[ 1  2  3]\n",
      " [11 12 13]\n",
      " [21 22 23]\n",
      " [31 32 33]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,40,10).reshape(4,1)\n",
    "print(\"a.shape =\",a.shape)\n",
    "print('a:\\n',a)\n",
    "\n",
    "b = np.arange(1,4)\n",
    "print(\"\\nb.shape =\",b.shape)\n",
    "print('b:\\n',b)\n",
    "\n",
    "print('\\na + b:\\n',a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upcasting <a id='H36'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed earlier that when we created an array from a list that contained both integers and floating point numbers, the resulting array had a `float64` data type. `Numpy` noticed that the data types in the list did not match and performed what is called `upcasting`. Whenever a situation like this occurs, `numpy` will always choose the most precise data type and cast each element as that data type. Because floating point numbers are more precise than integers, the integers were cast as floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]] \n",
      "\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "myList = [[1.0, 2.0, 3.0],[4, 5, 6]]\n",
    "a = np.array(myList)\n",
    "\n",
    "print(a, '\\n')\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Upcasting` also occurs when performing numerical operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [0 1 2 3 4 5] \n",
      "\n",
      "a Data Type: int32 \n",
      "\n",
      "b:\n",
      " [0.98763621 0.00743969 0.5607724  0.62347624 0.35429875 0.71658622] \n",
      "\n",
      "b Data Type:\n",
      " float64 \n",
      "\n",
      "a:\n",
      " [0.98763621 1.00743969 2.5607724  3.62347624 4.35429875 5.71658622] \n",
      "\n",
      "a + b Data Type: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(6)\n",
    "b = np.random.random(6)\n",
    "\n",
    "print('a:\\n', a, '\\n')\n",
    "print('a Data Type:', a.dtype, '\\n')\n",
    "\n",
    "print('b:\\n', b, '\\n')\n",
    "print('b Data Type:\\n', b.dtype, '\\n')\n",
    "\n",
    "\n",
    "NewArray = a + b\n",
    "print('a:\\n', NewArray, '\\n')\n",
    "print('a + b Data Type:', NewArray.dtype, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal Functions <a id='H37'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Functions, or `ufuncs`, are functions that be applied element-wise on an array. The following table describes some common `ufuncs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ufunc    | Interpretation \n",
    ":----    | :---- \n",
    "`np.exp` | Natural Exponentiation\n",
    "`np.sqrt`| Square Root\n",
    "`np.sin` | Sine\n",
    "`np.cos` | Cosine\n",
    "`np.log` | Natural Logarithm\n",
    "`np.isinf`  | Check For Infinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [1 2 3 4 5] \n",
      "\n",
      "np.exp(a):\n",
      " [  2.71828183   7.3890561   20.08553692  54.59815003 148.4131591 ] \n",
      "\n",
      "np.sqrt(a):\n",
      " [1.         1.41421356 1.73205081 2.         2.23606798] \n",
      "\n",
      "np.log(a):\n",
      " [0.         0.69314718 1.09861229 1.38629436 1.60943791] \n",
      "\n",
      "np.isinf(a):\n",
      " [False False False False False] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,6)\n",
    "\n",
    "print('a:\\n', a, '\\n')\n",
    "\n",
    "print('np.exp(a):\\n', np.exp(a), '\\n')\n",
    "print('np.sqrt(a):\\n', np.sqrt(a), '\\n')\n",
    "print('np.log(a):\\n', np.log(a), '\\n')\n",
    "print('np.isinf(a):\\n', np.isinf(a), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing <a id='H38'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing is a very important skill to learn when using `numpy`. The syntax resembles that of Python but comes with some new features. These examples will be implemented on a 2-dimensional array but follows the same logic for higher-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(16).reshape(4,4)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing uses each axis as a reference. To index the first row of a multidimensional array, we index as we normally do in base Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To index a specific element, we use more than one index, separated by a comma. This example tells `numpy` to look at index `0` in the rows dimension and to look at index `2` in the column dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(a[0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To index the first *column* of a multidimensional array, we use the `:` operator and a comma. This is telling `numpy` to look at every row but only index the first element of each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  8 12]\n"
     ]
    }
   ],
   "source": [
    "print(a[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, using the `:` operator for the first and second axis dimensions tells `numpy` to extract every row and every column. yielding a `view` of the original array. Note that all indexing operations will return a `view` rather than `copy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "print(a[:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this array is only `2` dimensions. We cannot index any more than `2` dimensions. Doing so will yield an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-1d4a5b2adc8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "print(a[2,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use ranges while indexes. This example tells `numpy` that we want the first `2` rows and every column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3]\n",
      " [4 5 6 7]]\n"
     ]
    }
   ],
   "source": [
    "print(a[0:2, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ranges in multiple dimensions when indexing. This example tells `numpy` that we want the first `2` rows and the first `3` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0:2,0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can index a row out of a `numpy` array, then index that row itself. Operations like this are not exclusive to indexing or `numpy` and is called `chaining`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(a[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# some index chaining\n",
    "print(a[:,:3][:2,:][1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas <a id='H39'></a>\n",
    "\n",
    "* [Pandas](#H39)\n",
    "\t* [Introduction](#H40)\n",
    "\t* [Creating A Series](#H42)\n",
    "\t* [Creating a Dataframe](#H44)\n",
    "\t\t* [Attributes](#H45)\n",
    "\t\t* [Slicing a DataFrame](#H49)\n",
    "\t* [Reading In Data](#H54)\n",
    "\t* [Looking At Data](#H58)\n",
    "\t* [Manipulating Data](#H63)\n",
    "\t\t* [Column Operations](#H64)\n",
    "\t\t* [Broadcasting](#H66)\n",
    "\t\t* [Modifying a Column](#H67)\n",
    "\t\t* [Adding a New Column](#H68)\n",
    "\t\t* [Working with Strings](#H69)\n",
    "\t\t* [The `pandas.to_numeric` Function](#H72)\n",
    "\t\t* [Working with Dates](#H73)\n",
    "\t\t* [Missing Values](#H76)\n",
    "\t* [Subsetting Data](#H80)\n",
    "\t\t* [Subsetting by Boolean Expressions](#H81)\n",
    "\t\t* [Dropping Rows and Columns](#H82)\n",
    "\t* [Analyzing Data](#H85)\n",
    "\t\t* [Descriptive Statistics](#H86)\n",
    "\t\t* [The `value_counts` Function](#H87)\n",
    "\t\t* [Sampling](#H88)\n",
    "\t\t* [Group By/Aggregate](#H89)\n",
    "\t* [Exporting Data](#H90)\n",
    "\t\t* [`to_csv`](#H91)\n",
    "\t\t* [`to_json`](#H92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='H40'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` is a package built on top of `numpy` that excels at manipulating and cleaning data. There are two major objects that can be created with Pandas:\n",
    "\n",
    "* Series\n",
    "    - Can be thought of as a \"column\" of data\n",
    "    - Comparable to a `numpy` array object\n",
    "    - All entries in a Series must have the same data type\n",
    "* DataFrame\n",
    "    - A rectangular dataset\n",
    "    - Has columns and rows of data\n",
    "    - Can hold heterogeneous data between columns\n",
    "    - It a container that is collection of Series objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aliasing <a id='H41'></a>\n",
    "\n",
    "`Pandas` is commonly aliased as `pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating A Series <a id='H42'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Series` object, the `pandas.Series()` function needs to be called. The argument for this function can be many data structures but lists and dictionaries are used the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Sayonara\n",
      "1     Racecar\n",
      "2    Carousel\n",
      "3        Pony\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series([\"Sayonara\", \"Racecar\", \"Carousel\", \"Pony\"])  # call the Series function with a list\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index and Slicing a Series <a id='H43'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left side of the printed `Series` are the row numbers. This acts as the index for a `Series`. Indexing and Slicing from `numpy` can be applied here. If more than one element is extracting from slicing, then a **view** of the `Series` is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Racecar\n"
     ]
    }
   ],
   "source": [
    "print(s[1])  # index the element in the Series at index 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    Carousel\n",
      "3        Pony\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(s[2:4]) # index the elements from index 2 up to but not including index 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a list of index values to slice a `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Sayonara\n",
      "1     Racecar\n",
      "3        Pony\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "indexes = [0,1,3]\n",
    "\n",
    "print(s[indexes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of `Series` objects can be changed as well. The values of the indexes do not have to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 1    Sayonara\n",
      "Song 2     Racecar\n",
      "Song 3    Carousel\n",
      "Song 4        Pony\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "s = pd.Series(\n",
    "    data = [\"Sayonara\", \"Racecar\", \"Carousel\", \"Pony\"],\n",
    "    index = [\"Song 1\", \"Song 2\", \"Song 3\",\"Song 4\"])  # create a custom index,\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These custom indexes can be useful to index the `Series` in another way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pony\n"
     ]
    }
   ],
   "source": [
    "print(s[\"Song 4\"])  # index the element in the series with the index \"Song 4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is still possible to index a `Series` using the traditional `numpy` slicing techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song 2     Racecar\n",
      "Song 3    Carousel\n",
      "Song 4        Pony\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(s[1:4]) # index the elements from index 1 up to but not including index 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Dataframe <a id='H44'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataframes` are an ordered collection of `Series`. The words `column` or `Series` are used **interchangeably** when referring to a vertical column in a `DataFrame`. To create a `DataFrame` object, the `pandas.DataFrame()` function needs to be called. The argument for this function is generally a `numpy` array or a Python dictionary. Initialized `Dataframes` are commonly assigned the name `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Name    Occupation        Born        Died  Age\n",
      "Index 1  Rosaline Franklin       Chemist  1920-07-25  1958-04-16   37\n",
      "Index 2     William Gosset  Statistician  1876-06-13  1937-10-16   61\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe \n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Rosaline Franklin', 'William Gosset'],\n",
    "    'Occupation': ['Chemist', 'Statistician'],\n",
    "    'Born': ['1920-07-25', '1876-06-13'],\n",
    "    'Died': ['1958-04-16', '1937-10-16'],\n",
    "    'Age': [37, 61]},\n",
    "    index = [\"Index 1\", \"Index 2\"])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes <a id='H45'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape <a id='H46'></a>\n",
    "\n",
    "Similar to `numpy` arrays, the `shape` attribute tells us the length of the rows and columns of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n",
      "\n",
      "Number of Rows: 2\n",
      "Number of Columns: 5\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "print(\"\\nNumber of Rows:\", df.shape[0])\n",
    "print(\"Number of Columns:\", df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns <a id='H47'></a>\n",
    "\n",
    "The `columns` attribute returns a **list-like** object of the column names of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Occupation', 'Born', 'Died', 'Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index <a id='H48'></a>\n",
    "\n",
    "Similarly, the `index` attribute returns a **list-like** object of the index names or row names of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Index 1', 'Index 2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing a DataFrame <a id='H49'></a>\n",
    "\n",
    "Slicing `DataFrames` can have a slightly different syntax than `Series`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing a Column <a id='H50'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract a single column from a `DataFrame`, you can use the column name wrapped in square brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1    Rosaline Franklin\n",
      "Index 2       William Gosset\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 1    37\n",
      "Index 2    61\n",
      "Name: Age, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract more than one column from a `DataFrame`, use a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Occupation        Died  Age\n",
      "Index 1       Chemist  1958-04-16   37\n",
      "Index 2  Statistician  1937-10-16   61\n"
     ]
    }
   ],
   "source": [
    "cols = [\"Occupation\", \"Died\", \"Age\"] # list of column names\n",
    "\n",
    "print(df[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing a Row <a id='H51'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two methods to slice a row:\n",
    "* **pandas.iloc** : Slices the Dataframe by the row position index\n",
    "* **pandas.loc** : Slices the Dataframe by the name of the Index\n",
    "\n",
    "Notice that the row that is extracted from the `DataFrame` is also a `Series`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          Rosaline Franklin\n",
      "Occupation              Chemist\n",
      "Born                 1920-07-25\n",
      "Died                 1958-04-16\n",
      "Age                          37\n",
      "Name: Index 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])  # this will extract the first row of the dataframe, regardless of index name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          Rosaline Franklin\n",
      "Occupation              Chemist\n",
      "Born                 1920-07-25\n",
      "Died                 1958-04-16\n",
      "Age                          37\n",
      "Name: Index 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[\"Index 1\"]) # this will extract the row or rows named \"Index 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting a Single Data Point <a id='H52'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.loc` and `pandas.iloc` can also be used to extract single pieces of data.\n",
    "\n",
    "* pandas.iloc[ ROW_INDEX, COLUMN_INDEX]\n",
    "* pandas.loc[ ROW_NAME, COLUMN_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemist\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0,1])  # extract first row and second column of the dataframe, regardless of index or column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920-07-25\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[\"Index 1\", \"Born\"]) # extract the row or rows named \"Index 1\" and the column named \"Born\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting More Than One Data Point <a id='H53'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `pandas.iloc` function and lists of column and row indices, you can slice a dataframe however you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Occupation        Died  Age\n",
      "Index 1       Chemist  1958-04-16   37\n",
      "Index 2  Statistician  1937-10-16   61\n"
     ]
    }
   ],
   "source": [
    "cols = [1, 3, 4]     # list of column indices\n",
    "inds = [0, 1]        # List of row indices\n",
    "\n",
    "print(df.iloc[inds, cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, by using the `pandas.loc` function and lists of column and row names, you can slice a dataframe however you choose and accomplish the same task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Occupation        Died  Age\n",
      "Index 1       Chemist  1958-04-16   37\n",
      "Index 2  Statistician  1937-10-16   61\n"
     ]
    }
   ],
   "source": [
    "cols = [\"Occupation\", \"Died\", \"Age\"] # list of column names\n",
    "inds = [\"Index 1\", \"Index 2\"]        # List of index names\n",
    "\n",
    "print(df.loc[inds, cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading In Data <a id='H54'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we want to read in a dataset from a file. Pandas has functions that make this process easy for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pandas.read_csv` function <a id='H55'></a>\n",
    "\n",
    "One of the most common file types for storing data is a `.csv` file. The `read_csv()` function will read in a `.csv` file and store it as a `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             5.1          3.5           1.4          0.2     Setosa\n",
      "1             4.9          3.0           1.4          0.2     Setosa\n",
      "2             4.7          3.2           1.3          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          0.2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           6.2          3.4           5.4          2.3  Virginica\n",
      "149           5.9          3.0           5.1          1.8  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#                 FILE LOCATION    \n",
    "iris = pd.read_csv(\"./iris.csv\")\n",
    "\n",
    "# print the dataframe\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `header` argument <a id='H56'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset you are trying to read in does not have any column names, make use of the `header` argument in the function declaration. This will tell `pandas` that the file does not have any column names. Let's demonstrate this example on the `iris.csv` dataset. Because this data **does** have column names, the first entry in the dataset at index `0` are the column names. While this should not be done in practice, it does demonstrate the utility of the `header` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0            1             2            3          4\n",
      "0    sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "1             5.1          3.5           1.4           .2     Setosa\n",
      "2             4.9            3           1.4           .2     Setosa\n",
      "3             4.7          3.2           1.3           .2     Setosa\n",
      "4             4.6          3.1           1.5           .2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "146           6.7            3           5.2          2.3  Virginica\n",
      "147           6.3          2.5             5          1.9  Virginica\n",
      "148           6.5            3           5.2            2  Virginica\n",
      "149           6.2          3.4           5.4          2.3  Virginica\n",
      "150           5.9            3           5.1          1.8  Virginica\n",
      "\n",
      "[151 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#                    FILE LOCATION       # Use if dataset has no column names\n",
    "iris = pd.read_csv(   \"./iris.csv\"   ,     header = None)\n",
    "\n",
    "# print dataset\n",
    "print(iris) # because this dataset has column names, the column names will be rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correct this error, let's reassign the `iris` variable so that the `DataFrame` has headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                 FILE LOCATION    \n",
    "iris = pd.read_csv(\"./iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the function is called `read_csv`, it has more uses than just reading in **Comma Separated Value** (CSV) files. It can read in any **character delimited file**, like **Tab Separated Value** (TSV) files.\n",
    "\n",
    "\n",
    "Let's read in the `gapminder.tsv` file. Because this file separates the values using a tab rather than a comma, we have to declare the `delimiter` argument as `\\t` which is the **escape character** for a tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                         FILE LOCATION    DELIMITER SET TO TAB\n",
    "Gapminder = pd.read_csv('./gapminder.tsv', delimiter= '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pandas.read_json` function <a id='H57'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular file type for storing data is a `.json` file. These files look like large **nested** Python dictionaries. A **truncated** version of the `Advertising.json` file is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <- Outer Dictionary        <br>                      \n",
    "&emsp;\"TV\": {  &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <- Inner Dictionary        <br> \n",
    "    &emsp;&emsp;\"0\": 230.1,<br>\n",
    "    &emsp;&emsp;\"1\": 44.5,<br>\n",
    " ...<br>\n",
    "    &emsp;&emsp;\"198\": 283.6,<br>\n",
    "    &emsp;&emsp;\"199\": 232.1<br>\n",
    "  &emsp;},<br>\n",
    "&emsp;\"Radio\": { &emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp; <- Inner Dictionary        <br> \n",
    "   &emsp;&emsp; \"0\": 37.8,<br>\n",
    "    &emsp;&emsp;\"1\": 39.3,<br>\n",
    " ...<br>\n",
    "    &emsp;&emsp;\"198\": 42,<br>\n",
    "    &emsp;&emsp;\"199\": 8.6<br>\n",
    "  &emsp;},<br>\n",
    "  &emsp;\"Newspaper\": { &emsp;&emsp;&emsp;&nbsp; <- Inner Dictionary        <br> \n",
    "   &emsp;&emsp; \"0\": 69.2,<br>\n",
    "    &emsp;&emsp;\"1\": 45.1,<br>\n",
    "...<br>\n",
    "    &emsp;&emsp;\"198\": 66.2,<br>\n",
    "    &emsp;&emsp;\"199\": 8.7<br>\n",
    "  &emsp;},<br>\n",
    "  &emsp;\"Sales\": { &emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <- Inner Dictionary        <br> \n",
    "    &emsp;&emsp;\"0\": 22.1,<br>\n",
    "   &emsp;&emsp; \"1\": 10.4,<br>\n",
    "...<br>\n",
    "    &emsp;&emsp;\"198\": 25.5,<br>\n",
    "    &emsp;&emsp;\"199\": 13.4<br>\n",
    "  &emsp;}<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in a `.json` file, simply use the `read_json()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales\n",
      "0    230.1   37.8       69.2   22.1\n",
      "1     44.5   39.3       45.1   10.4\n",
      "2     17.2   45.9       69.3    9.3\n",
      "3    151.5   41.3       58.5   18.5\n",
      "4    180.8   10.8       58.4   12.9\n",
      "..     ...    ...        ...    ...\n",
      "195   38.2    3.7       13.8    7.6\n",
      "196   94.2    4.9        8.1    9.7\n",
      "197  177.0    9.3        6.4   12.8\n",
      "198  283.6   42.0       66.2   25.5\n",
      "199  232.1    8.6        8.7   13.4\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#                             FILE LOCATION \n",
    "Advertising = pd.read_json(\"./Advertising.json\")\n",
    "\n",
    "\n",
    "print(Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking At Data <a id='H58'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at some methods to look at our data. You have already seen the print method, which generally prints the first 5 and last 5 entries in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          country continent  year  lifeExp       pop   gdpPercap\n",
      "0     Afghanistan      Asia  1952   28.801   8425333  779.445314\n",
      "1     Afghanistan      Asia  1957   30.332   9240934  820.853030\n",
      "2     Afghanistan      Asia  1962   31.997  10267083  853.100710\n",
      "3     Afghanistan      Asia  1967   34.020  11537966  836.197138\n",
      "4     Afghanistan      Asia  1972   36.088  13079460  739.981106\n",
      "...           ...       ...   ...      ...       ...         ...\n",
      "1699     Zimbabwe    Africa  1987   62.351   9216418  706.157306\n",
      "1700     Zimbabwe    Africa  1992   60.377  10704340  693.420786\n",
      "1701     Zimbabwe    Africa  1997   46.809  11404948  792.449960\n",
      "1702     Zimbabwe    Africa  2002   39.989  11926563  672.038623\n",
      "1703     Zimbabwe    Africa  2007   43.487  12311143  469.709298\n",
      "\n",
      "[1704 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# print the dataset\n",
    "print(Gapminder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### head <a id='H59'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head()` method function returns the first 5 entries in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country continent  year  lifeExp       pop   gdpPercap\n",
      "0  Afghanistan      Asia  1952   28.801   8425333  779.445314\n",
      "1  Afghanistan      Asia  1957   30.332   9240934  820.853030\n",
      "2  Afghanistan      Asia  1962   31.997  10267083  853.100710\n",
      "3  Afghanistan      Asia  1967   34.020  11537966  836.197138\n",
      "4  Afghanistan      Asia  1972   36.088  13079460  739.981106\n"
     ]
    }
   ],
   "source": [
    "# print the first 5 entries of the dataframe\n",
    "print(Gapminder.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add a number as an argument to the `head()` method function, it will return that many entries from the beginning of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country continent  year  lifeExp       pop   gdpPercap\n",
      "0  Afghanistan      Asia  1952   28.801   8425333  779.445314\n",
      "1  Afghanistan      Asia  1957   30.332   9240934  820.853030\n",
      "2  Afghanistan      Asia  1962   31.997  10267083  853.100710\n",
      "3  Afghanistan      Asia  1967   34.020  11537966  836.197138\n",
      "4  Afghanistan      Asia  1972   36.088  13079460  739.981106\n",
      "5  Afghanistan      Asia  1977   38.438  14880372  786.113360\n",
      "6  Afghanistan      Asia  1982   39.854  12881816  978.011439\n",
      "7  Afghanistan      Asia  1987   40.822  13867957  852.395945\n",
      "8  Afghanistan      Asia  1992   41.674  16317921  649.341395\n",
      "9  Afghanistan      Asia  1997   41.763  22227415  635.341351\n"
     ]
    }
   ],
   "source": [
    "# print the first 10 entries of the dataframe\n",
    "print(Gapminder.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tail <a id='H60'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tail()` method function will return the last 5 entries from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country continent  year  lifeExp       pop   gdpPercap\n",
      "1699  Zimbabwe    Africa  1987   62.351   9216418  706.157306\n",
      "1700  Zimbabwe    Africa  1992   60.377  10704340  693.420786\n",
      "1701  Zimbabwe    Africa  1997   46.809  11404948  792.449960\n",
      "1702  Zimbabwe    Africa  2002   39.989  11926563  672.038623\n",
      "1703  Zimbabwe    Africa  2007   43.487  12311143  469.709298\n"
     ]
    }
   ],
   "source": [
    "# print the last 5 entries of the dataframe\n",
    "print(Gapminder.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, if we add a number as an argument to the `tail()` method function, it will return that many entries from the **end** of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country continent  year  lifeExp       pop   gdpPercap\n",
      "1696  Zimbabwe    Africa  1972   55.635   5861135  799.362176\n",
      "1697  Zimbabwe    Africa  1977   57.674   6642107  685.587682\n",
      "1698  Zimbabwe    Africa  1982   60.363   7636524  788.855041\n",
      "1699  Zimbabwe    Africa  1987   62.351   9216418  706.157306\n",
      "1700  Zimbabwe    Africa  1992   60.377  10704340  693.420786\n",
      "1701  Zimbabwe    Africa  1997   46.809  11404948  792.449960\n",
      "1702  Zimbabwe    Africa  2002   39.989  11926563  672.038623\n",
      "1703  Zimbabwe    Africa  2007   43.487  12311143  469.709298\n"
     ]
    }
   ],
   "source": [
    "# print the last 8 entries of the dataframe\n",
    "print(Gapminder.tail(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### describe <a id='H61'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `describe()` method function will return descriptive statistics on each of the `numerical` columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             year      lifeExp           pop      gdpPercap\n",
      "count  1704.00000  1704.000000  1.704000e+03    1704.000000\n",
      "mean   1979.50000    59.474439  2.960121e+07    7215.327081\n",
      "std      17.26533    12.917107  1.061579e+08    9857.454543\n",
      "min    1952.00000    23.599000  6.001100e+04     241.165877\n",
      "25%    1965.75000    48.198000  2.793664e+06    1202.060309\n",
      "50%    1979.50000    60.712500  7.023596e+06    3531.846989\n",
      "75%    1993.25000    70.845500  1.958522e+07    9325.462346\n",
      "max    2007.00000    82.603000  1.318683e+09  113523.132900\n"
     ]
    }
   ],
   "source": [
    "print(Gapminder.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### info <a id='H62'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `info()` method function will return a summary of each of the columns including their data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1704 entries, 0 to 1703\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   country    1704 non-null   object \n",
      " 1   continent  1704 non-null   object \n",
      " 2   year       1704 non-null   int64  \n",
      " 3   lifeExp    1704 non-null   float64\n",
      " 4   pop        1704 non-null   int64  \n",
      " 5   gdpPercap  1704 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 80.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(Gapminder.info()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Data <a id='H63'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Operations <a id='H64'></a>\n",
    "\n",
    "Similar to `numpy` arrays, operations on `DataFrame` columns or `Series` are done element-wise, regardless of shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV Budget Column Shape:  (200,)\n",
      "Newspaper Budget Column Shape:  (200,)\n",
      "Radio Budget Column Shape:  (200,)\n",
      "\n",
      "Total Budget:\n",
      " 0      337.1\n",
      "1      128.9\n",
      "2      132.4\n",
      "3      251.3\n",
      "4      250.0\n",
      "       ...  \n",
      "195     55.7\n",
      "196    107.2\n",
      "197    192.7\n",
      "198    391.8\n",
      "199    249.4\n",
      "Length: 200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"TV Budget Column Shape: \",Advertising[\"TV\"].shape)\n",
    "print(\"Newspaper Budget Column Shape: \",Advertising[\"Newspaper\"].shape)\n",
    "print(\"Radio Budget Column Shape: \",Advertising[\"Radio\"].shape)\n",
    "\n",
    "# New Series = TV Budget Column  + Newspaper Budget Column  + Radio Budget Column\n",
    "TotalBudget  = Advertising[\"TV\"] + Advertising[\"Newspaper\"] + Advertising[\"Radio\"]\n",
    "\n",
    "# print the new series\n",
    "print('\\nTotal Budget:\\n',TotalBudget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape Mismatching <a id='H65'></a>\n",
    "\n",
    "If the column shapes differ among the operands, then something interesting will happen. The shape of the smaller `Series` is **broadcast** and missing rows of the `Series` are filled with `NaN` values, which means **Not a Number**. Any arithmetic operation with a `Nan` value will always result in a `Nan` value. The example below shows how the first four rows of the summation of the `Series` are properly computed, but the rest of the rows are filled with `NaN` values. Operations like this where the shapes of the columns do not match result in a **loss of data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV Budget Column:\n",
      " 0      230.1\n",
      "1       44.5\n",
      "2       17.2\n",
      "3      151.5\n",
      "4      180.8\n",
      "       ...  \n",
      "195     38.2\n",
      "196     94.2\n",
      "197    177.0\n",
      "198    283.6\n",
      "199    232.1\n",
      "Name: TV, Length: 200, dtype: float64\n",
      "\n",
      "Column Shape:  (200,)\n",
      "\n",
      "---------------\n",
      "New Series:\n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "dtype: int64\n",
      "\n",
      "Series Shape:  (4,)\n",
      "\n",
      "---------------\n",
      "TV Budget Column + New Series:\n",
      " 0      231.1\n",
      "1       46.5\n",
      "2       20.2\n",
      "3      155.5\n",
      "4        NaN\n",
      "       ...  \n",
      "195      NaN\n",
      "196      NaN\n",
      "197      NaN\n",
      "198      NaN\n",
      "199      NaN\n",
      "Length: 200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"TV Budget Column:\\n\",Advertising[\"TV\"])\n",
    "print(\"\\nColumn Shape: \",Advertising[\"TV\"].shape)\n",
    "print(\"\\n---------------\")\n",
    "\n",
    "mySeries = pd.Series([1,2,3,4])\n",
    "print(\"New Series:\\n\", mySeries)\n",
    "print(\"\\nSeries Shape: \",mySeries.shape)\n",
    "print(\"\\n---------------\")\n",
    "\n",
    "print(\"TV Budget Column + New Series:\\n\",Advertising[\"TV\"] + mySeries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting <a id='H66'></a>\n",
    "\n",
    "However, single **scalar** broadcasting operations still work as expected. The following operation adds 1 to each row of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      231.1\n",
      "1       45.5\n",
      "2       18.2\n",
      "3      152.5\n",
      "4      181.8\n",
      "       ...  \n",
      "195     39.2\n",
      "196     95.2\n",
      "197    178.0\n",
      "198    284.6\n",
      "199    233.1\n",
      "Name: TV, Length: 200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Advertising[\"TV\"] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying a Column <a id='H67'></a>\n",
    "\n",
    "So far, we have yet to change a single column of any `DataFrame` we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales\n",
      "0    230.1   37.8       69.2   22.1\n",
      "1     44.5   39.3       45.1   10.4\n",
      "2     17.2   45.9       69.3    9.3\n",
      "3    151.5   41.3       58.5   18.5\n",
      "4    180.8   10.8       58.4   12.9\n",
      "..     ...    ...        ...    ...\n",
      "195   38.2    3.7       13.8    7.6\n",
      "196   94.2    4.9        8.1    9.7\n",
      "197  177.0    9.3        6.4   12.8\n",
      "198  283.6   42.0       66.2   25.5\n",
      "199  232.1    8.6        8.7   13.4\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# advertising dataframe has been unaltered\n",
    "print(Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify a column, we simply reassign a new Series to a column of a `Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlteredColumn:\n",
      " 0     -230.1\n",
      "1      -44.5\n",
      "2      -17.2\n",
      "3     -151.5\n",
      "4     -180.8\n",
      "       ...  \n",
      "195    -38.2\n",
      "196    -94.2\n",
      "197   -177.0\n",
      "198   -283.6\n",
      "199   -232.1\n",
      "Name: TV, Length: 200, dtype: float64\n",
      "\n",
      "--------------\n",
      "\n",
      "Updated DataFrame:\n",
      "         TV  Radio  Newspaper  Sales\n",
      "0   -230.1   37.8       69.2   22.1\n",
      "1    -44.5   39.3       45.1   10.4\n",
      "2    -17.2   45.9       69.3    9.3\n",
      "3   -151.5   41.3       58.5   18.5\n",
      "4   -180.8   10.8       58.4   12.9\n",
      "..     ...    ...        ...    ...\n",
      "195  -38.2    3.7       13.8    7.6\n",
      "196  -94.2    4.9        8.1    9.7\n",
      "197 -177.0    9.3        6.4   12.8\n",
      "198 -283.6   42.0       66.2   25.5\n",
      "199 -232.1    8.6        8.7   13.4\n",
      "\n",
      "[200 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a new Series that is an alteration of an existing series\n",
    "AlteredColumn = Advertising[\"TV\"] * -1\n",
    "\n",
    "print(\"AlteredColumn:\\n\", AlteredColumn)\n",
    "print('\\n--------------')\n",
    "\n",
    "# reassign new Series to TV Budget Column\n",
    "Advertising[\"TV\"] = AlteredColumn\n",
    "\n",
    "# TV Budget Column has been updated\n",
    "print('\\nUpdated DataFrame:\\n',Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a New Column <a id='H68'></a>\n",
    "\n",
    "Adding a new column works similar to modifying an existing column, except you provide a new name for the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Budget:\n",
      " 0     -123.1\n",
      "1       39.9\n",
      "2       98.0\n",
      "3      -51.7\n",
      "4     -111.6\n",
      "       ...  \n",
      "195    -20.7\n",
      "196    -81.2\n",
      "197   -161.3\n",
      "198   -175.4\n",
      "199   -214.8\n",
      "Length: 200, dtype: float64\n",
      "\n",
      "-----------------\n",
      "\n",
      "Altered DataFrame:\n",
      "         TV  Radio  Newspaper  Sales  TotalBudget\n",
      "0   -230.1   37.8       69.2   22.1       -123.1\n",
      "1    -44.5   39.3       45.1   10.4         39.9\n",
      "2    -17.2   45.9       69.3    9.3         98.0\n",
      "3   -151.5   41.3       58.5   18.5        -51.7\n",
      "4   -180.8   10.8       58.4   12.9       -111.6\n",
      "..     ...    ...        ...    ...          ...\n",
      "195  -38.2    3.7       13.8    7.6        -20.7\n",
      "196  -94.2    4.9        8.1    9.7        -81.2\n",
      "197 -177.0    9.3        6.4   12.8       -161.3\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "199 -232.1    8.6        8.7   13.4       -214.8\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# New Series = TV Budget Column  + Newspaper Budget Column  + Radio Budget Column\n",
    "TotalBudget  = Advertising[\"TV\"] + Advertising[\"Newspaper\"] + Advertising[\"Radio\"]\n",
    "\n",
    "# print the new series\n",
    "print('\\nTotal Budget:\\n',TotalBudget)\n",
    "print('\\n-----------------')\n",
    "\n",
    "# assign TotalBudget to a new column called \"TotalBudget\"\n",
    "Advertising[\"TotalBudget\"] = TotalBudget\n",
    "\n",
    "# print the altered dataframe\n",
    "print('\\nAltered DataFrame:\\n',Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Strings <a id='H69'></a>\n",
    "\n",
    "Some columns will have type `string`. Arithmetic Operations on columns of this data type are also performed **element-wise** and work similar to Base Python string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          country continent  year  lifeExp       pop   gdpPercap\n",
      "0     Afghanistan      Asia  1952   28.801   8425333  779.445314\n",
      "1     Afghanistan      Asia  1957   30.332   9240934  820.853030\n",
      "2     Afghanistan      Asia  1962   31.997  10267083  853.100710\n",
      "3     Afghanistan      Asia  1967   34.020  11537966  836.197138\n",
      "4     Afghanistan      Asia  1972   36.088  13079460  739.981106\n",
      "...           ...       ...   ...      ...       ...         ...\n",
      "1699     Zimbabwe    Africa  1987   62.351   9216418  706.157306\n",
      "1700     Zimbabwe    Africa  1992   60.377  10704340  693.420786\n",
      "1701     Zimbabwe    Africa  1997   46.809  11404948  792.449960\n",
      "1702     Zimbabwe    Africa  2002   39.989  11926563  672.038623\n",
      "1703     Zimbabwe    Africa  2007   43.487  12311143  469.709298\n",
      "\n",
      "[1704 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Gapminder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Afghanistan,Asia\n",
      "1       Afghanistan,Asia\n",
      "2       Afghanistan,Asia\n",
      "3       Afghanistan,Asia\n",
      "4       Afghanistan,Asia\n",
      "              ...       \n",
      "1699     Zimbabwe,Africa\n",
      "1700     Zimbabwe,Africa\n",
      "1701     Zimbabwe,Africa\n",
      "1702     Zimbabwe,Africa\n",
      "1703     Zimbabwe,Africa\n",
      "Length: 1704, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# new Series =  Country Column      + comma +    Continent Column\n",
    "Location     = Gapminder[\"country\"] +  \",\"  + Gapminder[\"continent\"]\n",
    "\n",
    "# print new Series\n",
    "print(Location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `str.split` Function <a id='H70'></a>\n",
    "\n",
    "If we want to split a column into 2 separate columns, we can make use of the `.str` methods. These methods will tell Pandas to view the columns as a string column and opens up the use of string-based operations found in Base Python. The example below shows a split operation on the `Location` Series that was created. The result is a Series where each row is a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Afghanistan, Asia]\n",
      "1       [Afghanistan, Asia]\n",
      "2       [Afghanistan, Asia]\n",
      "3       [Afghanistan, Asia]\n",
      "4       [Afghanistan, Asia]\n",
      "               ...         \n",
      "1699     [Zimbabwe, Africa]\n",
      "1700     [Zimbabwe, Africa]\n",
      "1701     [Zimbabwe, Africa]\n",
      "1702     [Zimbabwe, Africa]\n",
      "1703     [Zimbabwe, Africa]\n",
      "Length: 1704, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Use the str methods and split to split each row on a comma.\n",
    "print(Location.str.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract the elements out of these lists using the `.str` method again and indexing the positions of the elements we want to extract from the lists. The resulting object is still a `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Afghanistan\n",
      "1       Afghanistan\n",
      "2       Afghanistan\n",
      "3       Afghanistan\n",
      "4       Afghanistan\n",
      "           ...     \n",
      "1699       Zimbabwe\n",
      "1700       Zimbabwe\n",
      "1701       Zimbabwe\n",
      "1702       Zimbabwe\n",
      "1703       Zimbabwe\n",
      "Length: 1704, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Use the str methods and split to split each row on a comma.\n",
    "# Then use the str method and index to extract the first element of each list\n",
    "print(Location.str.split(\",\").str[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `str.replace` Function <a id='H71'></a>\n",
    "\n",
    "The `str.replace()` function works similar to the Base Python `replace()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Afgh*nist*n,Asi*\n",
      "1       Afgh*nist*n,Asi*\n",
      "2       Afgh*nist*n,Asi*\n",
      "3       Afgh*nist*n,Asi*\n",
      "4       Afgh*nist*n,Asi*\n",
      "              ...       \n",
      "1699     Zimb*bwe,Afric*\n",
      "1700     Zimb*bwe,Afric*\n",
      "1701     Zimb*bwe,Afric*\n",
      "1702     Zimb*bwe,Afric*\n",
      "1703     Zimb*bwe,Afric*\n",
      "Length: 1704, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace all lowercase \"a\" with \"*\"\n",
    "print(Location.str.replace(\"a\", \"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `pandas.to_numeric` Function <a id='H72'></a>\n",
    "\n",
    "Let's say we have a column that has a string type but all of the strings are numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       2\n",
      "2    3.14\n",
      "3       5\n",
      "dtype: object\n",
      "\n",
      "Data Type:  object\n"
     ]
    }
   ],
   "source": [
    "# create a sample column\n",
    "nums = pd.Series([\"1\", \"2\", \"3.14\", \"5\"])\n",
    "\n",
    "# print the series\n",
    "print(nums)\n",
    "\n",
    "# print the data type\n",
    "print('\\nData Type: ',nums.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `pandas.to_numeric()` function to turn each of strings in the column into a numeric data type. This will return a new `Series` that has elements that are all numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.00\n",
      "1    2.00\n",
      "2    3.14\n",
      "3    5.00\n",
      "dtype: float64\n",
      "\n",
      "Data Type:  float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.to_numeric(nums))\n",
    "\n",
    "# print the data type\n",
    "print('\\nData Type: ',pd.to_numeric(nums).dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not all the values in the column can be interpreted as numeric, then an error will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"*egd\" at position 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"*egd\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-1660eee5b095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"3.14\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"*egd\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             values = lib.maybe_convert_numeric(\n\u001b[0m\u001b[0;32m    153\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             )\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"*egd\" at position 4"
     ]
    }
   ],
   "source": [
    "# create a sample column\n",
    "nums = pd.Series([\"1\", \"2\", \"3.14\", \"5\", \"*egd\"])\n",
    "\n",
    "print(pd.to_numeric(nums))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we use the `errors` argument, we can **coerce** these bad strings to interpreted as **NaN** values. These data types will be discussed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1.00\n",
      "1    2.00\n",
      "2    3.14\n",
      "3    5.00\n",
      "4     NaN\n",
      "dtype: float64\n",
      "\n",
      "Data Type:  float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.to_numeric(nums, errors= \"coerce\"))\n",
    "\n",
    "# print the data type\n",
    "print('\\nData Type: ',pd.to_numeric(nums, errors= \"coerce\").dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Dates <a id='H73'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in the `scientists.csv` file. The dataset contains the day of birth and death for 8 influential scientists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name        Born        Died  Age          Occupation\n",
      "0     Rosaline Franklin  1920-07-25  1958-04-16   37             Chemist\n",
      "1        William Gosset  1876-06-13  1937-10-16   61        Statistician\n",
      "2  Florence Nightingale  1820-05-12  1910-08-13   90               Nurse\n",
      "3           Marie Curie  1867-11-07  1934-07-04   66             Chemist\n",
      "4         Rachel Carson  1907-05-27  1964-04-14   56           Biologist\n",
      "5             John Snow  1813-03-15  1858-06-16   45           Physician\n",
      "6           Alan Turing  1912-06-23  1954-06-07   41  Computer Scientist\n",
      "7          Johann Gauss  1777-04-30  1855-02-23   77       Mathematician\n"
     ]
    }
   ],
   "source": [
    "scientists = pd.read_csv(\"scientists.csv\")\n",
    "\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `Born` column. The data type of this column is `object` which is used for columns that are all **strings** or a **mixed** data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1920-07-25\n",
      "1    1876-06-13\n",
      "2    1820-05-12\n",
      "3    1867-11-07\n",
      "4    1907-05-27\n",
      "5    1813-03-15\n",
      "6    1912-06-23\n",
      "7    1777-04-30\n",
      "Name: Born, dtype: object\n",
      "\n",
      "Data Type:  object\n"
     ]
    }
   ],
   "source": [
    "# extract the 'born' column\n",
    "Born = scientists[\"Born\"]\n",
    "\n",
    "# print the column\n",
    "print(Born)\n",
    "\n",
    "# print the data type of the 'Born' column\n",
    "print(\"\\nData Type: \", Born.dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what kind of data type the first entry in this column is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Entry in Column: 1920-07-25\n",
      "Data Type of Entry: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First Entry in Column:\", Born[0])\n",
    "print(\"Data Type of Entry:\", type(Born[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pd.to_datetime` Function <a id='H74'></a>\n",
    "\n",
    "Pandas implements a special data type for dates and time variables called `datetime`. However, columns are never assumed to be a `datetime` type so you have to explicitly declare a column as a `datetime` type. The `pd.to_datetime()` function turns a column with a string data type into a column with the `datetime` data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   1920-07-25\n",
      "1   1876-06-13\n",
      "2   1820-05-12\n",
      "3   1867-11-07\n",
      "4   1907-05-27\n",
      "5   1813-03-15\n",
      "6   1912-06-23\n",
      "7   1777-04-30\n",
      "Name: Born, dtype: datetime64[ns]\n",
      "\n",
      "Data Type:  datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# cast the Born column as a datetime type and assign to BornDT\n",
    "BornDT = pd.to_datetime(Born)\n",
    "\n",
    "# print the column\n",
    "print(BornDT)\n",
    "\n",
    "# print the data type of the 'BornDT' column\n",
    "print(\"\\nData Type: \", BornDT.dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries in the `BornDT`column are no longer strings and are now `datetime` types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Entry in Column: 1920-07-25 00:00:00\n",
      "Data Type of Entry: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First Entry in Column:\", BornDT[0])\n",
    "print(\"Data Type of Entry:\", type(BornDT[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then update the `Born` column of the `scientists` DataFrame with the new `datetime` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign BornDT to the \"Born\" column\n",
    "scientists[\"Born\"] = BornDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Died` column is also a date. we can update that column using only one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the 'Died' column, convert it to datetime, then reassign to the 'Died' column\n",
    "scientists[\"Died\"] = pd.to_datetime(scientists[\"Died\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see the data type of the `Born` and `Died` columns have been updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Name        8 non-null      object        \n",
      " 1   Born        8 non-null      datetime64[ns]\n",
      " 2   Died        8 non-null      datetime64[ns]\n",
      " 3   Age         8 non-null      int64         \n",
      " 4   Occupation  8 non-null      object        \n",
      "dtypes: datetime64[ns](2), int64(1), object(2)\n",
      "memory usage: 448.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(scientists.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations with DateTime columns and TimeDeltas <a id='H75'></a>\n",
    "\n",
    "Columns or Series that are of the same size and are both `datetime` types can have arithmetic operations performed on them. Note that the data type the entries in the new `Age` variable is now `timedelta` which is not a **timestamp** but a difference between two **timestamps**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   13779 days\n",
      "1   22404 days\n",
      "2   32964 days\n",
      "3   24345 days\n",
      "4   20777 days\n",
      "5   16529 days\n",
      "6   15324 days\n",
      "7   28422 days\n",
      "dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "Age = scientists[\"Died\"] - scientists[\"Born\"]\n",
    "\n",
    "print(Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform scalar broadcasting operations on `timedelta` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   27558 days\n",
      "1   44808 days\n",
      "2   65928 days\n",
      "3   48690 days\n",
      "4   41554 days\n",
      "5   33058 days\n",
      "6   30648 days\n",
      "7   56844 days\n",
      "dtype: timedelta64[ns]\n"
     ]
    }
   ],
   "source": [
    "print(Age * 2) # perform this operation element-wise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to extract only this values out of this Age column, we use the `dt.days` attribute. This will create a Series of just the day values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    13779\n",
      "1    22404\n",
      "2    32964\n",
      "3    24345\n",
      "4    20777\n",
      "5    16529\n",
      "6    15324\n",
      "7    28422\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "days = Age.dt.days\n",
    "\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a column in the `scientists` DataFrame called `Days` and assign the newly created Series to this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Name       Born       Died  Age          Occupation   Days\n",
      "0     Rosaline Franklin 1920-07-25 1958-04-16   37             Chemist  13779\n",
      "1        William Gosset 1876-06-13 1937-10-16   61        Statistician  22404\n",
      "2  Florence Nightingale 1820-05-12 1910-08-13   90               Nurse  32964\n",
      "3           Marie Curie 1867-11-07 1934-07-04   66             Chemist  24345\n",
      "4         Rachel Carson 1907-05-27 1964-04-14   56           Biologist  20777\n",
      "5             John Snow 1813-03-15 1858-06-16   45           Physician  16529\n",
      "6           Alan Turing 1912-06-23 1954-06-07   41  Computer Scientist  15324\n",
      "7          Johann Gauss 1777-04-30 1855-02-23   77       Mathematician  28422\n"
     ]
    }
   ],
   "source": [
    "scientists[\"Days\"] = days\n",
    "\n",
    "print(scientists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values <a id='H76'></a>\n",
    "\n",
    "Missing Values in datasets are a very common occurrence in real life datasets. So far, we have only looked as clean data. Next, we will explore topics and methods for handling missing data. Let's start by creating a sample `DataFrame` that has missing values. To create this, we will use `np.nan` to signify a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Street Name  Street Number        City\n",
      "0      Hawthorn Way            NaN  Washington\n",
      "1     Crescent Road          123.0      Boston\n",
      "2     Somerset Road         1529.0    San Jose\n",
      "3               NaN           54.0      Austin\n",
      "4  Charlotte Street         1219.0         NaN\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe with missing values from a dictionary\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Street Name\": ['Hawthorn Way', 'Crescent Road', 'Somerset Road', np.nan, 'Charlotte Street' ],\n",
    "        \"Street Number\": [np.nan, 123, 1529, 54, 1219],\n",
    "        \"City\": [\"Washington\", \"Boston\", \"San Jose\", \"Austin\", np.nan]\n",
    "    })\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pandas.isnull` Function <a id='H77'></a>\n",
    "\n",
    "The `pandas.isnull()` function can be applied to a `DataFrame` or a `Series` and will return a **boolean** `DataFrame` or `Series` of the same shape telling us which entries in the data are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Street Name  Street Number   City\n",
      "0        False           True  False\n",
      "1        False          False  False\n",
      "2        False          False  False\n",
      "3         True          False  False\n",
      "4        False          False   True\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pandas.dropna` Function <a id='H78'></a>\n",
    "\n",
    "Sometimes, it may be necessary to remove all rows which have missing data in them. The `pandas.dropna()` function can accomplish this. The returned `DataFrame` will be a subset of the original that does not have any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Street Name  Street Number      City\n",
      "1  Crescent Road          123.0    Boston\n",
      "2  Somerset Road         1529.0  San Jose\n"
     ]
    }
   ],
   "source": [
    "# drop all rows that have missing data\n",
    "print(df.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `subset` argument is used, then only rows with missing data in the selected columns will be dropped. Rows with missing data in columns not specified in this argument are left untouched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Street Name  Street Number      City\n",
      "1     Crescent Road          123.0    Boston\n",
      "2     Somerset Road         1529.0  San Jose\n",
      "4  Charlotte Street         1219.0       NaN\n"
     ]
    }
   ],
   "source": [
    "# drop all rows with missing values that occur in the \"Street Name\" or \"Street Number\" columns\n",
    "print(df.dropna( subset= [\"Street Name\", \"Street Number\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `axis` argument set to `1` to specify that we want to drop columns that have missing data. Because every column in this sample data has at least one entry that is missing, the resulting `DataFrame` is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# drop all columns that have missing data\n",
    "print(df.dropna(axis= 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pandas.fillna` Function <a id='H79'></a>\n",
    "\n",
    "Rather than removing missing data, we may want to fill the missing data points with values of our choosing. The `pandas.fillna()` function can accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Street Name Street Number        City\n",
      "0      Hawthorn Way          FILL  Washington\n",
      "1     Crescent Road           123      Boston\n",
      "2     Somerset Road          1529    San Jose\n",
      "3              FILL            54      Austin\n",
      "4  Charlotte Street          1219        FILL\n"
     ]
    }
   ],
   "source": [
    "# replace all missing values in DataFrame with \"FILL\"\n",
    "print(df.fillna(\"FILL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply this function to a single column and it generally makes more sense to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Washington\n",
      "1        Boston\n",
      "2      San Jose\n",
      "3        Austin\n",
      "4    Washington\n",
      "Name: City, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# replace all missing values in \"City\" column with \"Washington\"\n",
    "print(df[\"City\"].fillna(\"Washington\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting Data <a id='H80'></a>\n",
    "\n",
    "The following section will cover more advanced topics on how to slice and access subsets of a `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting by Boolean Expressions <a id='H81'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the `Sales` column out of the `Advertising` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      22.1\n",
      "1      10.4\n",
      "2       9.3\n",
      "3      18.5\n",
      "4      12.9\n",
      "       ... \n",
      "195     7.6\n",
      "196     9.7\n",
      "197    12.8\n",
      "198    25.5\n",
      "199    13.4\n",
      "Name: Sales, Length: 200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# get the 'Sales' column\n",
    "Sales = Advertising['Sales']\n",
    "print(Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a **boolean expression** on this Series and it will return a series of True and False values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       True\n",
      "1      False\n",
      "2      False\n",
      "3       True\n",
      "4      False\n",
      "       ...  \n",
      "195    False\n",
      "196    False\n",
      "197    False\n",
      "198     True\n",
      "199    False\n",
      "Name: Sales, Length: 200, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(Sales > 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we put this **boolean** Series in brackets, we can subset the rows of the DataFrame with only entries where the condition is True. Note that `subset` only has 75 of the original 200 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales  TotalBudget\n",
      "0   -230.1   37.8       69.2   22.1       -123.1\n",
      "3   -151.5   41.3       58.5   18.5        -51.7\n",
      "11  -214.7   24.0        4.0   17.4       -186.7\n",
      "14  -204.1   32.9       46.0   19.0       -125.2\n",
      "15  -195.4   47.7       52.9   22.4        -94.8\n",
      "..     ...    ...        ...    ...          ...\n",
      "187 -191.1   28.7       18.2   17.3       -144.2\n",
      "188 -286.0   13.9        3.7   15.9       -268.4\n",
      "193 -166.8   42.0        3.6   19.6       -121.2\n",
      "194 -149.7   35.6        6.0   17.3       -108.1\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "\n",
      "[75 rows x 5 columns]\n",
      "\n",
      "Shape of Original:  (200, 5)\n",
      "\n",
      "Shape of Subset:  (75, 5)\n"
     ]
    }
   ],
   "source": [
    "subset = Advertising[Sales > 15]\n",
    "\n",
    "print(subset)\n",
    "\n",
    "print(\"\\nShape of Original: \" , Advertising.shape)\n",
    "print(\"\\nShape of Subset: \" , subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this with more than one column and **boolean expression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      69.2\n",
      "1      45.1\n",
      "2      69.3\n",
      "3      58.5\n",
      "4      58.4\n",
      "       ... \n",
      "195    13.8\n",
      "196     8.1\n",
      "197     6.4\n",
      "198    66.2\n",
      "199     8.7\n",
      "Name: Newspaper, Length: 200, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# get the 'Newspaper' column\n",
    "Newspaper = Advertising['Newspaper']\n",
    "print(Newspaper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `&` operator to perform an **AND** operation on two **boolean** Series. If you need a refresher on boolean logic, refer to the truth tables in **Week 3**. Make note of the parentheses used for a grouped operation. IF these aren't included, an error may occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       True\n",
      "1      False\n",
      "2      False\n",
      "3       True\n",
      "4      False\n",
      "       ...  \n",
      "195    False\n",
      "196    False\n",
      "197    False\n",
      "198     True\n",
      "199    False\n",
      "Length: 200, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#       (Expression 1)  AND   (Expression 2)\n",
    "print(   (Sales > 15)    &   (Newspaper > 10)  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the use this resulting **boolean** Series to subset the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales  TotalBudget\n",
      "0   -230.1   37.8       69.2   22.1       -123.1\n",
      "3   -151.5   41.3       58.5   18.5        -51.7\n",
      "14  -204.1   32.9       46.0   19.0       -125.2\n",
      "15  -195.4   47.7       52.9   22.4        -94.8\n",
      "17  -281.4   39.6       55.8   24.4       -186.0\n",
      "..     ...    ...        ...    ...          ...\n",
      "183 -287.6   43.0       71.8   26.2       -172.8\n",
      "184 -253.8   21.3       30.0   17.6       -202.5\n",
      "185 -205.0   45.1       19.6   22.6       -140.3\n",
      "187 -191.1   28.7       18.2   17.3       -144.2\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "\n",
      "[61 rows x 5 columns]\n",
      "\n",
      "Length of Original:  (200, 5)\n",
      "\n",
      "Length of Subset:  (61, 5)\n"
     ]
    }
   ],
   "source": [
    "subset = Advertising[(Sales > 15) & (Newspaper > 10)]\n",
    "\n",
    "print(subset)\n",
    "\n",
    "print(\"\\nLength of Original: \" , Advertising.shape)\n",
    "print(\"\\nLength of Subset: \" , subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `|` operator to perform an **OR** operation on two **boolean** Series. This subset will return all rows where `Sales` is greater than `15` **OR** `Newspaper` is greater than `10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales  TotalBudget\n",
      "0   -230.1   37.8       69.2   22.1       -123.1\n",
      "1    -44.5   39.3       45.1   10.4         39.9\n",
      "2    -17.2   45.9       69.3    9.3         98.0\n",
      "3   -151.5   41.3       58.5   18.5        -51.7\n",
      "4   -180.8   10.8       58.4   12.9       -111.6\n",
      "..     ...    ...        ...    ...          ...\n",
      "192  -17.2    4.1       31.6    5.9         18.5\n",
      "193 -166.8   42.0        3.6   19.6       -121.2\n",
      "194 -149.7   35.6        6.0   17.3       -108.1\n",
      "195  -38.2    3.7       13.8    7.6        -20.7\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "\n",
      "[172 rows x 5 columns]\n",
      "\n",
      "Length of Original:  (200, 5)\n",
      "\n",
      "Length of Subset:  (172, 5)\n"
     ]
    }
   ],
   "source": [
    "#                    (Expression 1)   OR     (Expression 2)\n",
    "subset = Advertising[ (Sales > 15)    |    (Newspaper > 10)  ]\n",
    "print(subset)\n",
    "\n",
    "print(\"\\nLength of Original: \" , Advertising.shape)\n",
    "print(\"\\nLength of Subset: \" , subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Rows and Columns <a id='H82'></a>\n",
    "\n",
    "Another way to subset a `DataFrame` or `Series` is to drop rows or columns. Similar to subsetting, these operations will remove the rows and column specified in the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `pandas.drop` Function. <a id='H83'></a>\n",
    "\n",
    "This function accepts a list and will remove the index names specified in the list. Then it will return a view of the altered `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales  TotalBudget\n",
      "4   -180.8   10.8       58.4   12.9       -111.6\n",
      "5     -8.7   48.9       75.0    7.2        115.2\n",
      "6    -57.5   32.8       23.5   11.8         -1.2\n",
      "7   -120.2   19.6       11.6   13.2        -89.0\n",
      "8     -8.6    2.1        1.0    4.8         -5.5\n",
      "..     ...    ...        ...    ...          ...\n",
      "195  -38.2    3.7       13.8    7.6        -20.7\n",
      "196  -94.2    4.9        8.1    9.7        -81.2\n",
      "197 -177.0    9.3        6.4   12.8       -161.3\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "199 -232.1    8.6        8.7   13.4       -214.8\n",
      "\n",
      "[196 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop the index names 0,1,2,3 and return a view of the dataframe\n",
    "print(Advertising.drop([0,1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `columns` argument is used, the specified column names will be dropped and a view of the `DataFrame` will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Radio  Newspaper  Sales\n",
      "0     37.8       69.2   22.1\n",
      "1     39.3       45.1   10.4\n",
      "2     45.9       69.3    9.3\n",
      "3     41.3       58.5   18.5\n",
      "4     10.8       58.4   12.9\n",
      "..     ...        ...    ...\n",
      "195    3.7       13.8    7.6\n",
      "196    4.9        8.1    9.7\n",
      "197    9.3        6.4   12.8\n",
      "198   42.0       66.2   25.5\n",
      "199    8.6        8.7   13.4\n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop the column names \"TV\" and \"TotalBudget\" and return a view of the dataframe\n",
    "print(Advertising.drop(columns= [\"TV\",\"TotalBudget\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `inplace` Argument <a id='H84'></a>\n",
    "\n",
    "Once again, these methods have not altered the original `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales  TotalBudget\n",
      "0   -230.1   37.8       69.2   22.1       -123.1\n",
      "1    -44.5   39.3       45.1   10.4         39.9\n",
      "2    -17.2   45.9       69.3    9.3         98.0\n",
      "3   -151.5   41.3       58.5   18.5        -51.7\n",
      "4   -180.8   10.8       58.4   12.9       -111.6\n",
      "..     ...    ...        ...    ...          ...\n",
      "195  -38.2    3.7       13.8    7.6        -20.7\n",
      "196  -94.2    4.9        8.1    9.7        -81.2\n",
      "197 -177.0    9.3        6.4   12.8       -161.3\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "199 -232.1    8.6        8.7   13.4       -214.8\n",
      "\n",
      "[200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to change the original, we would have to reassign the newly altered `DataFrame` to the variable that stores the original `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales  TotalBudget\n",
      "4   -180.8   10.8       58.4   12.9       -111.6\n",
      "5     -8.7   48.9       75.0    7.2        115.2\n",
      "6    -57.5   32.8       23.5   11.8         -1.2\n",
      "7   -120.2   19.6       11.6   13.2        -89.0\n",
      "8     -8.6    2.1        1.0    4.8         -5.5\n",
      "..     ...    ...        ...    ...          ...\n",
      "195  -38.2    3.7       13.8    7.6        -20.7\n",
      "196  -94.2    4.9        8.1    9.7        -81.2\n",
      "197 -177.0    9.3        6.4   12.8       -161.3\n",
      "198 -283.6   42.0       66.2   25.5       -175.4\n",
      "199 -232.1    8.6        8.7   13.4       -214.8\n",
      "\n",
      "[196 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# drop the index names 0,1,2,3 and reassign it to Advertising\n",
    "Advertising = Advertising.drop([0,1,2,3])\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if we use the `inplace` argument set to `True`. A view of the altered `DataFrame` will not be returned and the original `DataFrame` will simply be updated with the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        TV  Radio  Newspaper  Sales\n",
      "4   -180.8   10.8       58.4   12.9\n",
      "5     -8.7   48.9       75.0    7.2\n",
      "6    -57.5   32.8       23.5   11.8\n",
      "7   -120.2   19.6       11.6   13.2\n",
      "8     -8.6    2.1        1.0    4.8\n",
      "..     ...    ...        ...    ...\n",
      "195  -38.2    3.7       13.8    7.6\n",
      "196  -94.2    4.9        8.1    9.7\n",
      "197 -177.0    9.3        6.4   12.8\n",
      "198 -283.6   42.0       66.2   25.5\n",
      "199 -232.1    8.6        8.7   13.4\n",
      "\n",
      "[196 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#                       columns to drop       do this operation in-place\n",
    "Advertising.drop(   columns= [\"TotalBudget\"],      inplace= True    )\n",
    "\n",
    "# The dataframe has been updated without having to reassign\n",
    "print(Advertising)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data <a id='H85'></a>\n",
    "\n",
    "The following section will cover useful tools for analyzing and understanding the data within a `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive Statistics <a id='H86'></a>\n",
    "\n",
    "Pandas offers methods to retrieve descriptive statistics about columns in our `DataFrame`. Let's start by extracting the `Sales` column for the `Advertising` Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4      12.9\n",
      "5       7.2\n",
      "6      11.8\n",
      "7      13.2\n",
      "8       4.8\n",
      "       ... \n",
      "195     7.6\n",
      "196     9.7\n",
      "197    12.8\n",
      "198    25.5\n",
      "199    13.4\n",
      "Name: Sales, Length: 196, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# get the 'Sales' column\n",
    "Sales = Advertising['Sales']\n",
    "print(Sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the `mean`, `min`, `max`, `standard deviation`, and `variance` from a column using the following method functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales.mean(): 14.001020408163264\n",
      "Sales.min(): 1.6\n",
      "Sales.max(): 27.0\n",
      "Sales.std(): 5.211594468312501\n",
      "Sales.var(): 27.16071690214546\n"
     ]
    }
   ],
   "source": [
    "print(\"Sales.mean():\", Sales.mean())\n",
    "print(\"Sales.min():\", Sales.min())\n",
    "print(\"Sales.max():\", Sales.max())\n",
    "print(\"Sales.std():\", Sales.std())\n",
    "print(\"Sales.var():\", Sales.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply these functions on a entire `DataFrame` and it will return a `Series` where the index name is a column name of the `DataFrame` and the values represent the descriptive statistics for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TV          -147.781633\n",
      "Radio         22.900510\n",
      "Newspaper     29.942347\n",
      "Sales         14.001020\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Advertising.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `mode()` method function always returns a `Series`. This is because more than one value may be tied for the most-occurring value in a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9.7\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# mode function returns a Series\n",
    "print(Sales.mode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the returned object from the `mode()` method function is a `Series`, we can simply extract the first and only value from it using indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.7\n"
     ]
    }
   ],
   "source": [
    "# get the mode and extract the first value from the Series\n",
    "print(Sales.mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `value_counts` Function <a id='H87'></a>\n",
    "\n",
    "This function works similarly to the `mode()` function but returns a `Series` with the each unique value as the index name and the counts of each of those unique value in a column. Notice how `9.7` is the most common value in the column. This is why the `mode()` function returns a `Series` object with only one element in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.7     5\n",
      "11.7    4\n",
      "12.9    4\n",
      "15.9    4\n",
      "13.2    3\n",
      "       ..\n",
      "22.4    1\n",
      "24.4    1\n",
      "5.9     1\n",
      "5.6     1\n",
      "16.7    1\n",
      "Name: Sales, Length: 119, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(Sales.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling <a id='H88'></a>\n",
    "\n",
    "Sometimes, it may be useful to extract a random number of rows from a `DataFrame`. The `sample()` function let's us choose the number of rows we want to randomly extract from the `DataFrame` and the `random_state` argument let's use put in a number as a **seed** so that we can rerun that random sampling many times and retrieve the same random sample of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        country continent  year  lifeExp        pop     gdpPercap\n",
      "864     Lebanon      Asia  1952   55.928    1439529   4834.804067\n",
      "1333     Serbia    Europe  1957   61.685    7271135   4981.090891\n",
      "861      Kuwait      Asia  1997   76.156    1765345  40300.619960\n",
      "801       Japan      Asia  1997   80.690  125956499  28816.584990\n",
      "242      Canada  Americas  1962   71.300   18985849  13462.485550\n",
      "892     Liberia    Africa  1972   42.614    1482628    803.005454\n",
      "1115  Nicaragua  Americas  2007   72.899    5675356   2749.320965\n",
      "108     Belgium    Europe  1952   68.000    8730405   8343.105127\n",
      "1489      Syria      Asia  1957   48.284    4149908   2117.234893\n",
      "1637  Venezuela  Americas  1977   67.456   13503563  13143.950950\n"
     ]
    }
   ],
   "source": [
    "#                      Number of Samples      seed for reproducibility\n",
    "print(Gapminder.sample(       n=10      ,        random_state = 23))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group By/Aggregate <a id='H89'></a>\n",
    "\n",
    "Sometimes, we want to look at rows of data that have trait in common. For example, let's look at the `iris` dataset. There are 3 different flower types in this dataset; **Versicolor**, **Virginica**, and, **Setosa**. We might want to see if the mean petal length is of these flowers are different from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             5.1          3.5           1.4          0.2     Setosa\n",
      "1             4.9          3.0           1.4          0.2     Setosa\n",
      "2             4.7          3.2           1.3          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          0.2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           6.2          3.4           5.4          2.3  Virginica\n",
      "149           5.9          3.0           5.1          1.8  Virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# take a peak at the iris data\n",
    "print(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we use the `.groupby()` function and use a column name as an argument. In this case, it would be the `variety` column. This function will **squeeze** all rows with the same attribute in the `variety` column into a single column and return a `DataFrameGroupBy` object. It is not possible to visualize this object, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000022D38B9BC40>\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "# create a DataFrameGroupBy object by combining rows with the same flower 'variety'\n",
    "grouped = iris.groupby(\"variety\")\n",
    "\n",
    "# You can not see what these objects look like\n",
    "print(grouped)\n",
    "print(type(grouped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can use the `aggregate()` function on the `DataFrameGroupBy` object and provide as an argument a list of descriptive statistics to perform on each of the **squeezed** rows. \n",
    "\n",
    "This example allows us to look that the mean petal length of the 3 types of flowers. From this we can see that on average, **Setosa** flowers have very small petal lengths compared to **Versicolor** and **Virginica** flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sepal.length      sepal.width      petal.length      petal.width  \\\n",
      "                   mean  min        mean  min         mean  min        mean   \n",
      "variety                                                                       \n",
      "Setosa            5.006  4.3       3.428  2.3        1.462  1.0       0.246   \n",
      "Versicolor        5.936  4.9       2.770  2.0        4.260  3.0       1.326   \n",
      "Virginica         6.588  4.9       2.974  2.2        5.552  4.5       2.026   \n",
      "\n",
      "                 \n",
      "            min  \n",
      "variety          \n",
      "Setosa      0.1  \n",
      "Versicolor  1.0  \n",
      "Virginica   1.4  \n"
     ]
    }
   ],
   "source": [
    "# aggregate on the grouped dataframe and return the mean and minimum of the squeezed rows\n",
    "print(grouped.aggregate(['mean', 'min']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This type of `DataFrame` is considered **multi-level** because it has more than one set of column names. Interacting with these types of `DataFrames` are outside the scope of this bootcamp but will be necessary to learn at some point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data <a id='H90'></a>\n",
    "\n",
    "Lastly, it will be important to export any `DataFrame` you have created or modified. The following methods can do just that. Let's export the sample `DataFrame` made in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Street Name  Street Number        City\n",
      "0      Hawthorn Way            NaN  Washington\n",
      "1     Crescent Road          123.0      Boston\n",
      "2     Somerset Road         1529.0    San Jose\n",
      "3               NaN           54.0      Austin\n",
      "4  Charlotte Street         1219.0         NaN\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `to_csv` <a id='H91'></a>\n",
    "\n",
    "This function will write the `DataFrame` as a **Comma Separated Value** (CSV) file. We can also use the `delimiter` argument to save the file using a different delimiter that a comma. Be sure to use the `index` argument and set it to `False` or the index names will also be saved as a column in the file. This is generally not needed.\n",
    "\n",
    "**Keep In Mind:** If the specified file already exists, it will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#          File Location    Don't write the index names to file\n",
    "df.to_csv( \"./Data.csv\",          index= False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `to_json` <a id='H92'></a>\n",
    "\n",
    "The `to_json()` function works similarly. Be sure to use the `.json` file type when exporting a `DataFrame` using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#           File Location   \n",
    "df.to_json(\"./Data.json\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "855d0e5e3014face4a7c77ef0d00c0f0d4790db1d0a64e73ac3b23cda8e76110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
